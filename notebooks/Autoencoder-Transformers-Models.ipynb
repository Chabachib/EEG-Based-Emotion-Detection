{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7420888,"sourceType":"datasetVersion","datasetId":4317501}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Emotion Detection\n## We will Build a neural network thatdetects human emotions from DEAP Datasets.\n\n<div style=\"text-align: center;\">\r\n    <img src=\"https://www.mdpi.com/sensors/sensors-22-08467/article_deploy/html/images/sensors-22-08467-g001.png\" width=\"800\" style=\"border-radius: 10px;\"/>\r\n</div>\r\n\n\n### Prerequisites\n\n\nYou'mne v1argparse, os, keras PyTorch, NumPy, machpickle, vision, and IPython in order to run this notebook on your machine.","metadata":{}},{"cell_type":"markdown","source":"## Emotion Detection using Autoencoders and LSTM Models\n\nEmotion detection leveraging Autoencoders and LSTM models combines feature extraction and sequence modeling to identify emotional states from input data such as text, audio, or physiological signals.\n\n## Autoderooder\n\n<div style=\"text-align: center;\">\n    <img src=\"https://www.assemblyai.com/blog/content/images/2022/01/autoencoder_architecture.png\" width=\"800\" style=\"border-radius: 10px;\"/>\n</div>\n\n\nThe **Autoencoder** serves as the feature extractor, capturing meaningful representations of the input data by encoding it into a compressed latent space. \n\n- The **Encoder** processes the input through a series of dense or convolutional layers (depending on the data type), reducing its dimensionality while preserving critical patterns. \n- The **Decoder** reconstructs the original input from the latent space to ensure the encoded features are informative and accurate.\n\n## LSTM (Long Short-Term Memory)\n\n<div style=\"text-align: center;\">\n    <img src=\"https://cdn.dida.do/new-project-3-1-1024x607-1024x585.webp\" width=\"800\" style=\"border-radius: 10px;\"/>\n</div>\n\n\nThe **LSTM** model is responsible for sequence modeling. \n\n- It processes sequential input, such as time-series data or sentence structures, by leveraging its ability to learn long-term dependencies. \n- The LSTM network operates on the features extracted by the Autoencoder, analyzing the temporal or contextual relationships to predict the corresponding emotional states.\n\n## Training Process\n\n1. **Autoencoder Training**: The Autoencoder is trained to minimize reconstruction error, ensuring high-quality feature extraction.\n2. **LSTM Training**: The LSTM model is fine-tuned using the features extracted by the Autoencoder to minimize emotion classification or regression loss.\n\nBy combining the strengths of both components, this architecture effectively detects and categorizes emotions, providing robust performance across diverse applications like:\n\n- Sentiment analysis\n- Affective computing","metadata":{}},{"cell_type":"markdown","source":"## Loading Libraries and DEAP Dataset\r\n\r\nFor emotion detection, we require a reliable dataset containing physiological signals and corresponding emotional labels. We'll use the **DEAP dataset**, a well-known resource for affective computing research, which includes EEG and peripheral physiological signals recorded from participants while watching videos.\r\n\r\n\"[DEAP: A Dataset for Emotion Analysis using Physiological Signals](http://www.eecs.qmul.ac.uk/mmv/datasets/deap/)\"\r\n\r\n### Libraries and Dataset Preparation\r\n\r\nWe'll begin by importing essential libraries such as TensorFlow, PyTorch, or other machine learning frameworks, along with tools for processing physiological signals. The DEAP dataset can be loaded using libraries like `numpy` and `scipy` to handle the provided `.mat` or `.bdf` files. Data preprocessing steps typically include:\r\n\r\n1. **Signal Filtering**: Applying band-pass filters to clean noise from raw EEG and physiological data.\r\n2. **Feature Extraction**: Extracting meaningful features such as power spectral density, time-domain features, or statistical metrics from the signals.\r\n3. **Label Mapping**: Mapping each signal to its corresponding emotional labels, such as valence, arousal, or dominance.\r\n\r\nThe DEAP dataset is suitable for training models to detect emotions by leveraging both the raw physiological signals and the extracted features.\r","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:36:32.459800Z","iopub.execute_input":"2024-11-28T13:36:32.460707Z","iopub.status.idle":"2024-11-28T13:36:32.928928Z","shell.execute_reply.started":"2024-11-28T13:36:32.460666Z","shell.execute_reply":"2024-11-28T13:36:32.928005Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input\n/kaggle/input/data_preprocessed_python\n/kaggle/input/Metadata\n/kaggle/input/audio_stimuli_MIDI\n/kaggle/input/metadata_xls\n/kaggle/input/audio_stimuli_MIDI_tempo24\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q mne==1.0","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:36:34.844345Z","iopub.execute_input":"2024-11-28T13:36:34.845008Z","iopub.status.idle":"2024-11-28T13:36:47.250933Z","shell.execute_reply.started":"2024-11-28T13:36:34.844974Z","shell.execute_reply":"2024-11-28T13:36:47.249834Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting mne==1.0\n  Downloading mne-1.0.0-py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.10/site-packages (from mne==1.0) (1.26.4)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from mne==1.0) (1.14.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mne==1.0) (3.7.5)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from mne==1.0) (4.66.4)\nRequirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.10/site-packages (from mne==1.0) (1.8.2)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from mne==1.0) (5.1.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mne==1.0) (21.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from mne==1.0) (3.1.4)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne==1.0) (3.11.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.5->mne==1.0) (2.32.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mne==1.0) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->mne==1.0) (2.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mne==1.0) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mne==1.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mne==1.0) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mne==1.0) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mne==1.0) (10.3.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mne==1.0) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mne==1.0) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (2024.8.30)\nDownloading mne-1.0.0-py3-none-any.whl (7.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: mne\n  Attempting uninstall: mne\n    Found existing installation: mne 1.8.0\n    Uninstalling mne-1.8.0:\n      Successfully uninstalled mne-1.8.0\nSuccessfully installed mne-1.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -q tensorflow==2.10.0","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:36:47.252760Z","iopub.execute_input":"2024-11-28T13:36:47.253058Z","iopub.status.idle":"2024-11-28T13:37:51.549037Z","shell.execute_reply.started":"2024-11-28T13:36:47.253032Z","shell.execute_reply":"2024-11-28T13:37:51.548059Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.10.0\n  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (24.3.25)\nCollecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.10.0)\n  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (1.62.2)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (3.11.0)\nCollecting keras<2.11,>=2.10.0 (from tensorflow==2.10.0)\n  Downloading keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.0)\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (18.1.1)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (21.3)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (1.16.0)\nCollecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n  Downloading tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (0.37.0)\nCollecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.0)\n  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.10.0) (1.16.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.43.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.30.0)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.32.3)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.10.0) (3.1.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.5)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\nDownloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nDownloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: gast\n    Found existing installation: gast 0.5.4\n    Uninstalling gast-0.5.4:\n      Successfully uninstalled gast-0.5.4\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.16.2\n    Uninstalling tensorboard-2.16.2:\n      Successfully uninstalled tensorboard-2.16.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.16.1\n    Uninstalling tensorflow-2.16.1:\n      Successfully uninstalled tensorflow-2.16.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ngoogle-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-datastore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-language 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-spanner 3.47.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-videointelligence 2.13.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nonnx 1.17.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.10.0 which is incompatible.\ntensorflow-serving-api 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.10.0 which is incompatible.\ntensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.10.0 which is incompatible.\ntf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from IPython.utils import io\nimport numpy as np\nimport numpy\nimport collections\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.utils import shuffle\n\nimport scipy.io\nfrom scipy import signal, integrate\nimport matplotlib.pyplot as plt\n\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, LSTM, Dropout\nfrom tensorflow.keras.models import load_model\n\nimport mne\nimport pickle\nimport math\nfrom sklearn.model_selection import train_test_split\n\nn_second = 60\nn_segment = 2*n_second-1\nn_points = n_second*128\nbottleneck = 12","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:37:51.550438Z","iopub.execute_input":"2024-11-28T13:37:51.551094Z","iopub.status.idle":"2024-11-28T13:37:57.863662Z","shell.execute_reply.started":"2024-11-28T13:37:51.551056Z","shell.execute_reply":"2024-11-28T13:37:57.862721Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-11-28 13:37:52.379571: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutex6unlockEv']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN4absl12lts_202308028StatusOrIN3tsl4core11RefCountPtrIS1_EEEEvEE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n/opt/conda/lib/python3.10/site-packages/mne/datasets/eegbci/eegbci.py:8: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  import pkg_resources\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Computes the power spectrum of signal X over specified frequency bands Band using the Fourier Transform and sums the power within each band.\n# Returns the power in each band and the power ratio (normalized power distribution) across all bands.\ndef bin_power(X, Band, Fs):\n    C = numpy.fft.fft(X)\n    C = abs(C)\n    Power = numpy.zeros(len(Band) - 1)\n    for Freq_Index in range(0, len(Band) - 1):\n        Freq = float(Band[Freq_Index])\n        Next_Freq = float(Band[Freq_Index + 1])\n        Power[Freq_Index] = sum(\n            C[int(numpy.floor(Freq / Fs * len(X))):\n                int(numpy.floor(Next_Freq / Fs * len(X)))]\n        )\n    Power_Ratio = Power / sum(Power)\n    return Power, Power_Ratio\n\n\n# Calculates the entropy of the power distribution in the frequency bands, representing the disorder or complexity of the signal.\n# Uses the bin_power function to compute power ratios if not provided, and returns the negative entropy value for each band.\ndef spectral_entropy(X, Band, Fs, Power_Ratio=None):\n    if Power_Ratio is None:\n        Power, Power_Ratio = bin_power(X, Band, Fs)\n\n    Spectral_Entropy = numpy.zeros(len(Power_Ratio))\n    for i in range(0, len(Power_Ratio)):\n        Spectral_Entropy[i] = Power_Ratio[i] * numpy.log(Power_Ratio[i])\n    # to save time, minus one is omitted\n    return -1 * Spectral_Entropy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:37:57.865890Z","iopub.execute_input":"2024-11-28T13:37:57.867156Z","iopub.status.idle":"2024-11-28T13:37:57.873482Z","shell.execute_reply.started":"2024-11-28T13:37:57.867125Z","shell.execute_reply":"2024-11-28T13:37:57.872650Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Normalization and Standarization","metadata":{}},{"cell_type":"code","source":"# build in\na = np.array([[1,2,3],[4,5,6],[7,8,9]])\nscaler = MinMaxScaler().fit(a)\na = scaler.transform(a)\nprint(a)\n\n#custom\na = np.array([[1,2,3],[4,5,6],[7,8,9]])\nmax_, min_ = np.amax(a), np.amin(a)\na = (a - min_) / (max_ - min_)\nprint(a)\n\ndef normalise_2D(a, multiple):\n    max_, min_ = np.amax(a), np.amin(a)\n    a = (a - min_) / (max_ - min_)\n    return multiple*a\n\na = np.array([[1,2,3],[4,5,6],[7,8,9]])\nnormalise_2D(a, 1) # range -10 to 10","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:37:57.874501Z","iopub.execute_input":"2024-11-28T13:37:57.874749Z","iopub.status.idle":"2024-11-28T13:38:00.201889Z","shell.execute_reply.started":"2024-11-28T13:37:57.874725Z","shell.execute_reply":"2024-11-28T13:38:00.200871Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[[0.  0.  0. ]\n [0.5 0.5 0.5]\n [1.  1.  1. ]]\n[[0.    0.125 0.25 ]\n [0.375 0.5   0.625]\n [0.75  0.875 1.   ]]\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([[0.   , 0.125, 0.25 ],\n       [0.375, 0.5  , 0.625],\n       [0.75 , 0.875, 1.   ]])"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# build in\na = np.array([[1,2,3],[4,5,6],[7,8,9]])\nscaler = StandardScaler().fit(a)\na = scaler.transform(a)\nprint(a)\n\n# custom\na = np.array([[1,2,3],[4,5,6],[7,8,9]])\nstd = np.std(a)\nmean = np.mean(a)\na = (a-mean)/std\nprint(a)\n\ndef standardise_2D(a, multiple):\n    std = np.std(a)\n    mean = np.mean(a)\n    a = (a-mean)/std\n    return multiple*a\n\na = np.array([[1,2,3],[4,5,6],[7,8,9]])\nstandardise_2D(a, 10)","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:38:00.203158Z","iopub.execute_input":"2024-11-28T13:38:00.203475Z","iopub.status.idle":"2024-11-28T13:38:00.215370Z","shell.execute_reply.started":"2024-11-28T13:38:00.203448Z","shell.execute_reply":"2024-11-28T13:38:00.214532Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[[-1.22474487 -1.22474487 -1.22474487]\n [ 0.          0.          0.        ]\n [ 1.22474487  1.22474487  1.22474487]]\n[[-1.54919334 -1.161895   -0.77459667]\n [-0.38729833  0.          0.38729833]\n [ 0.77459667  1.161895    1.54919334]]\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([[-15.49193338, -11.61895004,  -7.74596669],\n       [ -3.87298335,   0.        ,   3.87298335],\n       [  7.74596669,  11.61895004,  15.49193338]])"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### Data Loading And Preprocessing\n#### The idea it to create 2 datasets, one for arousal and another for valence to create hybrid models for both","metadata":{}},{"cell_type":"code","source":"def convertOneData(file_name):\n    with open(file_name, 'rb') as file:\n        mat = pickle.load(file, encoding='latin1')\n        labels = mat['labels'][:, 0:2] # only valence, arousal, no dominance, liking\n        data = mat['data'][:, 0:32, 3*128:] # only first 32 channels ['Fp1','AF3','F3','F7','FC5',\n        #'FC1','C3','T7','CP5','CP1','P3','P7','PO3','O1','Oz','Pz','Fp2','AF4','Fz','F4',\n        #'F8','FC6','FC2','Cz','C4','T8','CP6','CP2','P4','P8','PO4','O2']\n        #and skip first 3 seconds\n        #print(labels.shape, data.shape) # (40, 2) (40, 32, 8064)\n        valence_labels, valence_data = [], []\n        arousal_labels, arousal_data = [], []\n        for i, label in enumerate(labels):\n            valence, arousal = label[0], label[1]\n            if valence > 5.5: # value >5.5 is high\n                valence_labels.append(1)\n                valence_data.append(data[i])\n            if valence < 4.5: # value <4.5 is high\n                valence_labels.append(0)\n                valence_data.append(data[i])\n            if arousal > 5.5:\n                arousal_labels.append(1)\n                arousal_data.append(data[i])\n            if arousal < 4.5:\n                arousal_labels.append(0)\n                arousal_data.append(data[i])\n        \n        print(\"valence: \", len(valence_labels), \"arousal: \", len(arousal_labels))\n    return valence_labels, valence_data, arousal_labels, arousal_data        \n    \n\ndef convertAllData():\n    all_valence_labels, all_valence_data = [], []\n    all_arousal_labels, all_arousal_data = [], []\n    for i in range(32): \n        if i < 10: # subject 01-09\n            name = '%0*d' % (2,i+1)\n        else: # subject 10-32\n            name = i+1\n        file_name = \"/kaggle/input/data_preprocessed_python/s\"+str(name)+\".dat\"\n        print(file_name)\n        valence_labels, valence_data, arousal_labels, arousal_data = convertOneData(file_name) # convert one subject data\n        \n        all_valence_labels += valence_labels\n        for valence_d in valence_data: # each trial\n            valence_d = standardise_2D(valence_d, 1)\n            all_valence_data.append(valence_d)    \n        all_arousal_labels += arousal_labels\n        for arousal_d in arousal_data:\n            arousal_d = standardise_2D(arousal_d, 1)\n            all_arousal_data.append(arousal_d)\n     \n    all_valence_labels = np.array(all_valence_labels)\n    all_valence_data = np.array(all_valence_data)\n    all_arousal_labels = np.array(all_arousal_labels)\n    all_arousal_data = np.array(all_arousal_data)\n    print(\"Valence trial data for all subject: \", all_valence_labels.shape,all_valence_data.shape)\n    print(\"Arousal trial data for all subject: \", all_arousal_labels.shape,all_arousal_data.shape)\n    # save numpy array of total data to files\n    np.save('/kaggle/working/Data/processed_DEAP/valence/' + 'all_valence_labels.npy', all_valence_labels)\n    np.save('/kaggle/working/Data/processed_DEAP/valence/' + 'all_valence_data.npy', all_valence_data)\n    np.save('/kaggle/working/Data/processed_DEAP/arousal/' + 'all_arousal_labels.npy', all_arousal_labels)\n    np.save('/kaggle/working/Data/processed_DEAP/arousal/' + 'all_arousal_data.npy', all_arousal_data)","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:38:00.216827Z","iopub.execute_input":"2024-11-28T13:38:00.217144Z","iopub.status.idle":"2024-11-28T13:38:00.233323Z","shell.execute_reply.started":"2024-11-28T13:38:00.217109Z","shell.execute_reply":"2024-11-28T13:38:00.232627Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!mkdir /kaggle/working/Data/\n!mkdir /kaggle/working/Data/processed_DEAP/\n!mkdir /kaggle/working/Data/processed_DEAP/arousal/\n!mkdir /kaggle/working/Data/processed_DEAP/valence/\n!mkdir /kaggle/working/Results/\n!mkdir /kaggle/working/Results/autoencoder_model/\n!mkdir /kaggle/working/Results/LSTM_model/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:38:00.234183Z","iopub.execute_input":"2024-11-28T13:38:00.234448Z","iopub.status.idle":"2024-11-28T13:38:01.259068Z","shell.execute_reply.started":"2024-11-28T13:38:00.234425Z","shell.execute_reply":"2024-11-28T13:38:01.258073Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"convertAllData()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:38:01.260654Z","iopub.execute_input":"2024-11-28T13:38:01.261434Z","iopub.status.idle":"2024-11-28T13:38:02.271455Z","shell.execute_reply.started":"2024-11-28T13:38:01.261391Z","shell.execute_reply":"2024-11-28T13:38:02.270423Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def load_np_data(dimension):\n    if dimension == 'valence':\n        all_labels, all_data = np.load('/kaggle/working/Data/processed_DEAP/valence/' + 'all_valence_labels.npy', allow_pickle=True), np.load('/kaggle/working/Data/processed_DEAP/valence/' + 'all_valence_data.npy', allow_pickle=True)\n        print(\"Total valence: \", all_labels.shape, all_data.shape)\n        #print(\"High and low valence: \", collections.Counter(all_labels))# 587 high valence, 472 low valence\n    elif dimension == 'arousal':\n        all_labels, all_data = np.load('/kaggle/working/Data/processed_DEAP/arousal/' + 'all_arousal_labels.npy', allow_pickle=True), np.load('/kaggle/working/Data/processed_DEAP/arousal/' + 'all_arousal_data.npy', allow_pickle=True)\n        print(\"Total arousal: \", all_labels.shape, all_data.shape)\n        #print(\"High and low arousal: \", collections.Counter(all_labels))# 620 high arousal, 462 low arousal\n    return all_labels, all_data","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:38:43.932648Z","iopub.execute_input":"2024-11-28T13:38:43.933001Z","iopub.status.idle":"2024-11-28T13:38:43.939476Z","shell.execute_reply.started":"2024-11-28T13:38:43.932967Z","shell.execute_reply":"2024-11-28T13:38:43.938541Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"#### Loading data for each model","metadata":{}},{"cell_type":"code","source":"all_labels, all_data = load_np_data(dimension=\"valence\")\n#all_labels, all_data = load_np_data(dimension=\"arousal\")","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:38:43.940724Z","iopub.execute_input":"2024-11-28T13:38:43.941067Z","iopub.status.idle":"2024-11-28T13:38:44.746137Z","shell.execute_reply.started":"2024-11-28T13:38:43.941033Z","shell.execute_reply":"2024-11-28T13:38:44.745270Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total valence:  (1059,) (1059, 32, 7680)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# after standardised\nprint(np.amax(all_data)) # max value\nprint(np.amin(all_data)) # min value\n\n# print(np.amax(all_valence_data[0])) # max value\n# print(np.amin(all_valence_data[0])) # min value","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:38:44.747664Z","iopub.execute_input":"2024-11-28T13:38:44.748073Z","iopub.status.idle":"2024-11-28T13:38:53.632750Z","shell.execute_reply.started":"2024-11-28T13:38:44.748027Z","shell.execute_reply":"2024-11-28T13:38:53.631700Z"},"trusted":true},"outputs":[{"name":"stdout","text":"91.75265724740024\n-100.00674912321686\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"#### Feature Extraction\nWe will compute the Power Spectral Density (PSD) of EEG data across frequency bands for all channels and time segments using Welch’s method, and reshapes the PSD for integration-based band power calculation.\nIntegrating PSD values over specific frequency bands (e.g., delta, theta, alpha, beta) for each segment and channel, returning a flattened feature matrix representing band power.","metadata":{}},{"cell_type":"code","source":"def trial_psd_extraction_integration(data): # data shape (12, 8064)\n    info = mne.create_info(ch_names= ['1','2','3','4','5','6','7','8','9','10','11','12'], sfreq=128);\n    raw = mne.io.RawArray(data, info, first_samp=0, copy='auto', verbose=None);\n    psd_origin, f = mne.time_frequency.psd_welch(raw, fmin=0, fmax=60, n_fft=128, n_overlap=64, n_per_seg=128, picks='all', window='hann', average=None, verbose=None)# average='mean' or None\n    # print(psd_origin.shape, f.shape) # (12, 61, 125) (61,) 61 frequency\n    psd = np.moveaxis(psd_origin, -1, 0) # (125, 12, 61)\n    # calculate frequency band power using integration\n    band_power = [] # band power for all segments\n    for segment in psd:\n        segment_band_power = [] # band power for all channels in one segment\n        for psd_channel in segment:\n            y_int = integrate.cumulative_trapezoid(psd_channel, f, initial=0) # integrate to calculate band power\n            one_band_power = np.array([y_int[7]-y_int[4],y_int[13]-y_int[8],y_int[30]-y_int[14],y_int[51]-y_int[31]])\n            segment_band_power.append(one_band_power)\n        band_power.append(segment_band_power)\n    band_power = np.array(band_power) # (125, 12, 4)\n    band_power = np.moveaxis(band_power, -1, 1) # (125, 4, 12)\n    band_power = band_power.reshape((n_segment, bottleneck*4)) # flatten feature (125, 48)\n    band_power = 10*band_power\n    return band_power","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:38:53.634038Z","iopub.execute_input":"2024-11-28T13:38:53.634423Z","iopub.status.idle":"2024-11-28T13:38:54.873705Z","shell.execute_reply.started":"2024-11-28T13:38:53.634384Z","shell.execute_reply":"2024-11-28T13:38:54.872699Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"#### Vector transformations for ecoding and decoding","metadata":{}},{"cell_type":"code","source":"# change dimension from (849, 32, 7680)to (849, 8064, 32) then to (6846336, 32) for input 32-dimension vector to autoencoder\ndef vector_transform(data):\n    vectors = np.moveaxis(data, 1, -1)\n    vectors = vectors.reshape((vectors.shape[0]*vectors.shape[1], vectors.shape[2]))\n    return vectors\n\n# change output of autoencoder dimension from (6846336, 12) to (849, 8064, 12) then to (849, 12, 8064)\ndef inverse_vector_transform(vectors):\n    data = vectors.reshape((int(vectors.shape[0]/n_points), n_points, vectors.shape[1]))\n    data = np.moveaxis(data, -1, 1)\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-11-28T13:38:54.875007Z","iopub.execute_input":"2024-11-28T13:38:54.875493Z","iopub.status.idle":"2024-11-28T13:38:56.455447Z","shell.execute_reply.started":"2024-11-28T13:38:54.875442Z","shell.execute_reply":"2024-11-28T13:38:56.454092Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# **Multiple folds/models training (AutoEncoder + LSTM)**","metadata":{}},{"cell_type":"code","source":"all_data, all_labels = shuffle(all_data, all_labels, random_state=0)\nn = len(all_labels) # 1059\nprint(n)\nfold_n = math.floor(n/10) # 105\nprint(fold_n)\nall_data, all_labels = all_data[:10*fold_n], all_labels[:10*fold_n] # (1050, 32, 8064)  \nprint(all_data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:38:56.456894Z","iopub.execute_input":"2024-11-28T13:38:56.457178Z","iopub.status.idle":"2024-11-28T13:38:58.324120Z","shell.execute_reply.started":"2024-11-28T13:38:56.457152Z","shell.execute_reply":"2024-11-28T13:38:58.323191Z"}},"outputs":[{"name":"stdout","text":"1059\n105\n(1050, 32, 7680)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def process(test_fold_number):\n    # train has 9 folds, test has 1 fold\n    train_data = np.concatenate((all_data[:test_fold_number*fold_n], all_data[fold_n+test_fold_number*fold_n:]), axis=0)\n    train_labels = np.concatenate((all_labels[:test_fold_number*fold_n], all_labels[fold_n+test_fold_number*fold_n:]), axis=0)\n    test_data = all_data[test_fold_number*fold_n : fold_n+test_fold_number*fold_n]\n    test_labels = all_labels[test_fold_number*fold_n : fold_n+test_fold_number*fold_n]\n    print(train_data.shape,test_data.shape) # (945, 32, 8064) (105, 32, 8064)\n    \n    # change dimension to 32-dimension vector for input to autoencoder\n    train_vectors = vector_transform(train_data)\n    test_vectors = vector_transform(test_data)\n    print(train_vectors.shape, test_vectors.shape)# (7620480, 32) (846720, 32)\n    \n    # -------- Create new autoencoder --------\n    input_layer = Input(shape=(32,))\n    encoded = Dense(64, activation=None)(input_layer)\n    bottleneck_layer = Dense(bottleneck, activation=None)(encoded)\n    decoded = Dense(64, activation=None)(bottleneck_layer)\n    decoded = Dense(32, activation=None)(decoded)\n    autoencoder = Model(input_layer, decoded)\n    autoencoder.summary()\n\n    encoder = Model(input_layer, bottleneck_layer)\n    encoder.summary()\n\n    decoder_input_layer = Input(shape=(bottleneck,))\n    decoder_layer = autoencoder.layers[-2](decoder_input_layer)\n    decoder_layer = autoencoder.layers[-1](decoder_layer)\n    decoder = Model(decoder_input_layer, decoder_layer)\n    decoder.summary()\n    \n    # -------- Compile and train autoencoder --------\n    autoencoder.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n    autoencoder.fit(train_vectors, train_vectors, epochs=1, batch_size=64, shuffle=True, validation_data=(test_vectors, test_vectors))\n    autoencoder.save(\"/kaggle/working/Results/autoencoder_model/autoencoder_model_test_fold_\" + str(test_fold_number) + \".h5\")\n    \n    # -------- Encode train and test data by pass through encoder --------\n    train_data_encoded = encoder.predict(train_vectors)\n    train_data_encoded = inverse_vector_transform(train_data_encoded) \n    test_data_encoded = encoder.predict(test_vectors) \n    test_data_encoded = inverse_vector_transform(test_data_encoded) \n    print(\"Encoded training data shape: \", train_data_encoded.shape)\n    print(\"Encoded test data shape: \", test_data_encoded.shape)\n    \n    # -------- Feature extraction from 12 source signal --------\n    train_band_power = [] # band power feature sequence for train trials\n    for data in train_data_encoded: # for every train trial\n        with io.capture_output() as captured:\n            trial_band_power = trial_psd_extraction_integration(data) # data shape (12, 8064)\n        train_band_power.append(trial_band_power)\n    train_band_power = np.array(train_band_power)\n    \n    test_band_power = [] # band power feature sequence for test trials\n    for data in test_data_encoded: # for every test trial\n        with io.capture_output() as captured:\n            trial_band_power = trial_psd_extraction_integration(data) # data shape (12, 8064)\n        test_band_power.append(trial_band_power)\n    test_band_power = np.array(test_band_power)\n    print(\"All features of training data shape: \", train_band_power.shape) # shape (849, 125, 48)\n    print(\"All features of test data shape: \", test_band_power.shape) # shape (95, 125, 48)\n    \n    # -------- Create new LSTM model --------\n    x=Input(shape=(n_segment,bottleneck*4)) # flatten (12,4) to 48\n    x1=LSTM(n_segment)(x)\n    x2=Dense(n_segment)(x1)\n    x3=Dense(12)(x2)\n    output=Dense(1, activation=\"sigmoid\")(x2)\n    model=Model(x, output)\n\n    # -------- Compile and train LSTM --------\n    model.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n    history = model.fit(train_band_power, train_labels, epochs=30, batch_size=8, validation_data=(test_band_power, test_labels))\n    print(\"Hightest accuracy: \" + str(max(history.history['val_accuracy'])))\n    model.save(\"/kaggle/working/Results/LSTM_model/LSTM_model_test_fold_\" + str(test_fold_number) + \".h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:38:58.325446Z","iopub.execute_input":"2024-11-28T13:38:58.326114Z","iopub.status.idle":"2024-11-28T13:38:58.341229Z","shell.execute_reply.started":"2024-11-28T13:38:58.326071Z","shell.execute_reply":"2024-11-28T13:38:58.340295Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"for i in range(10):\n    print(\"********** Test Fold \" + str(i) + \" ************\")\n    process(i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T11:12:22.604266Z","iopub.execute_input":"2024-11-24T11:12:22.604645Z","iopub.status.idle":"2024-11-24T13:16:43.881255Z","shell.execute_reply.started":"2024-11-24T11:12:22.604580Z","shell.execute_reply":"2024-11-24T13:16:43.880404Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"********** Test Fold 0 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 32)]              0         \n                                                                 \n dense (Dense)               (None, 64)                2112      \n                                                                 \n dense_1 (Dense)             (None, 12)                780       \n                                                                 \n dense_2 (Dense)             (None, 64)                832       \n                                                                 \n dense_3 (Dense)             (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 32)]              0         \n                                                                 \n dense (Dense)               (None, 64)                2112      \n                                                                 \n dense_1 (Dense)             (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 12)]              0         \n                                                                 \n dense_2 (Dense)             (None, 64)                832       \n                                                                 \n dense_3 (Dense)             (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 162s 1ms/step - loss: 0.2251 - accuracy: 0.4501 - val_loss: 0.2227 - val_accuracy: 0.4460\n226800/226800 [==============================] - 215s 946us/step\n25200/25200 [==============================] - 23s 928us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 68ms/step - loss: 0.2559 - accuracy: 0.5259 - val_loss: 0.2557 - val_accuracy: 0.5429\nEpoch 2/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2390 - accuracy: 0.6063 - val_loss: 0.2554 - val_accuracy: 0.5238\nEpoch 3/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2305 - accuracy: 0.6296 - val_loss: 0.2547 - val_accuracy: 0.4857\nEpoch 4/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2257 - accuracy: 0.6444 - val_loss: 0.2546 - val_accuracy: 0.5333\nEpoch 5/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2194 - accuracy: 0.6624 - val_loss: 0.2443 - val_accuracy: 0.6000\nEpoch 6/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2175 - accuracy: 0.6772 - val_loss: 0.2481 - val_accuracy: 0.5048\nEpoch 7/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2114 - accuracy: 0.6942 - val_loss: 0.2491 - val_accuracy: 0.5333\nEpoch 8/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2069 - accuracy: 0.6963 - val_loss: 0.2470 - val_accuracy: 0.5429\nEpoch 9/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2034 - accuracy: 0.7005 - val_loss: 0.2546 - val_accuracy: 0.5048\nEpoch 10/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1979 - accuracy: 0.7058 - val_loss: 0.2429 - val_accuracy: 0.5429\nEpoch 11/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1938 - accuracy: 0.7228 - val_loss: 0.2527 - val_accuracy: 0.5143\nEpoch 12/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1918 - accuracy: 0.7228 - val_loss: 0.2610 - val_accuracy: 0.5524\nEpoch 13/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1855 - accuracy: 0.7376 - val_loss: 0.2431 - val_accuracy: 0.5714\nEpoch 14/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1827 - accuracy: 0.7418 - val_loss: 0.2435 - val_accuracy: 0.5619\nEpoch 15/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1787 - accuracy: 0.7503 - val_loss: 0.2475 - val_accuracy: 0.5524\nEpoch 16/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1738 - accuracy: 0.7587 - val_loss: 0.2534 - val_accuracy: 0.5714\nEpoch 17/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1718 - accuracy: 0.7630 - val_loss: 0.2665 - val_accuracy: 0.5429\nEpoch 18/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1680 - accuracy: 0.7725 - val_loss: 0.2508 - val_accuracy: 0.5429\nEpoch 19/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1621 - accuracy: 0.7820 - val_loss: 0.2681 - val_accuracy: 0.5238\nEpoch 20/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1606 - accuracy: 0.7979 - val_loss: 0.2542 - val_accuracy: 0.5238\nEpoch 21/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1571 - accuracy: 0.8053 - val_loss: 0.2466 - val_accuracy: 0.5524\nEpoch 22/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1545 - accuracy: 0.7894 - val_loss: 0.2610 - val_accuracy: 0.5333\nEpoch 23/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1503 - accuracy: 0.8032 - val_loss: 0.2561 - val_accuracy: 0.5238\nEpoch 24/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1457 - accuracy: 0.7989 - val_loss: 0.2428 - val_accuracy: 0.5810\nEpoch 25/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1463 - accuracy: 0.8074 - val_loss: 0.2396 - val_accuracy: 0.5714\nEpoch 26/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1417 - accuracy: 0.8138 - val_loss: 0.2772 - val_accuracy: 0.5524\nEpoch 27/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1367 - accuracy: 0.8190 - val_loss: 0.2631 - val_accuracy: 0.5524\nEpoch 28/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1346 - accuracy: 0.8233 - val_loss: 0.2627 - val_accuracy: 0.5619\nEpoch 29/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1299 - accuracy: 0.8275 - val_loss: 0.2853 - val_accuracy: 0.5333\nEpoch 30/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1292 - accuracy: 0.8265 - val_loss: 0.2511 - val_accuracy: 0.5619\nHightest accuracy: 0.6000000238418579\n********** Test Fold 1 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 32)]              0         \n                                                                 \n dense_7 (Dense)             (None, 64)                2112      \n                                                                 \n dense_8 (Dense)             (None, 12)                780       \n                                                                 \n dense_9 (Dense)             (None, 64)                832       \n                                                                 \n dense_10 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_5\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_4 (InputLayer)        [(None, 32)]              0         \n                                                                 \n dense_7 (Dense)             (None, 64)                2112      \n                                                                 \n dense_8 (Dense)             (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_6\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_5 (InputLayer)        [(None, 12)]              0         \n                                                                 \n dense_9 (Dense)             (None, 64)                832       \n                                                                 \n dense_10 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 167s 1ms/step - loss: 0.2258 - accuracy: 0.4494 - val_loss: 0.2219 - val_accuracy: 0.4533\n226800/226800 [==============================] - 215s 948us/step\n25200/25200 [==============================] - 24s 963us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 71ms/step - loss: 0.2533 - accuracy: 0.5280 - val_loss: 0.2640 - val_accuracy: 0.4571\nEpoch 2/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2388 - accuracy: 0.5894 - val_loss: 0.2631 - val_accuracy: 0.5048\nEpoch 3/30\n119/119 [==============================] - 8s 68ms/step - loss: 0.2317 - accuracy: 0.6042 - val_loss: 0.2590 - val_accuracy: 0.5048\nEpoch 4/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.2256 - accuracy: 0.6254 - val_loss: 0.2507 - val_accuracy: 0.5333\nEpoch 5/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.2202 - accuracy: 0.6413 - val_loss: 0.2519 - val_accuracy: 0.5238\nEpoch 6/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2159 - accuracy: 0.6698 - val_loss: 0.2490 - val_accuracy: 0.5524\nEpoch 7/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.2112 - accuracy: 0.6635 - val_loss: 0.2455 - val_accuracy: 0.5524\nEpoch 8/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2074 - accuracy: 0.6825 - val_loss: 0.2502 - val_accuracy: 0.5333\nEpoch 9/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.2044 - accuracy: 0.6931 - val_loss: 0.2501 - val_accuracy: 0.5524\nEpoch 10/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1980 - accuracy: 0.7079 - val_loss: 0.2478 - val_accuracy: 0.5333\nEpoch 11/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1934 - accuracy: 0.7122 - val_loss: 0.2430 - val_accuracy: 0.6000\nEpoch 12/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1882 - accuracy: 0.7386 - val_loss: 0.2436 - val_accuracy: 0.5714\nEpoch 13/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1866 - accuracy: 0.7333 - val_loss: 0.2501 - val_accuracy: 0.5619\nEpoch 14/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1813 - accuracy: 0.7439 - val_loss: 0.2569 - val_accuracy: 0.5429\nEpoch 15/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1793 - accuracy: 0.7323 - val_loss: 0.2525 - val_accuracy: 0.5429\nEpoch 16/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1737 - accuracy: 0.7492 - val_loss: 0.2623 - val_accuracy: 0.5333\nEpoch 17/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1692 - accuracy: 0.7640 - val_loss: 0.2737 - val_accuracy: 0.5333\nEpoch 18/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1677 - accuracy: 0.7640 - val_loss: 0.2581 - val_accuracy: 0.5714\nEpoch 19/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1630 - accuracy: 0.7831 - val_loss: 0.2639 - val_accuracy: 0.5143\nEpoch 20/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1555 - accuracy: 0.8011 - val_loss: 0.2673 - val_accuracy: 0.5714\nEpoch 21/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1533 - accuracy: 0.7958 - val_loss: 0.2942 - val_accuracy: 0.5238\nEpoch 22/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1503 - accuracy: 0.8074 - val_loss: 0.2788 - val_accuracy: 0.5143\nEpoch 23/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1448 - accuracy: 0.8063 - val_loss: 0.2870 - val_accuracy: 0.5429\nEpoch 24/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1432 - accuracy: 0.8190 - val_loss: 0.2824 - val_accuracy: 0.5238\nEpoch 25/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1398 - accuracy: 0.8286 - val_loss: 0.2736 - val_accuracy: 0.5714\nEpoch 26/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1344 - accuracy: 0.8423 - val_loss: 0.2763 - val_accuracy: 0.4952\nEpoch 27/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1297 - accuracy: 0.8455 - val_loss: 0.2608 - val_accuracy: 0.6000\nEpoch 28/30\n119/119 [==============================] - 8s 68ms/step - loss: 0.1263 - accuracy: 0.8466 - val_loss: 0.2857 - val_accuracy: 0.5238\nEpoch 29/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1224 - accuracy: 0.8561 - val_loss: 0.2851 - val_accuracy: 0.5333\nEpoch 30/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1172 - accuracy: 0.8593 - val_loss: 0.2906 - val_accuracy: 0.6000\nHightest accuracy: 0.6000000238418579\n********** Test Fold 2 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_8\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_7 (InputLayer)        [(None, 32)]              0         \n                                                                 \n dense_14 (Dense)            (None, 64)                2112      \n                                                                 \n dense_15 (Dense)            (None, 12)                780       \n                                                                 \n dense_16 (Dense)            (None, 64)                832       \n                                                                 \n dense_17 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_7 (InputLayer)        [(None, 32)]              0         \n                                                                 \n dense_14 (Dense)            (None, 64)                2112      \n                                                                 \n dense_15 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_10\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_8 (InputLayer)        [(None, 12)]              0         \n                                                                 \n dense_16 (Dense)            (None, 64)                832       \n                                                                 \n dense_17 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 167s 1ms/step - loss: 0.2256 - accuracy: 0.4474 - val_loss: 0.2211 - val_accuracy: 0.4694\n226800/226800 [==============================] - 212s 934us/step\n25200/25200 [==============================] - 24s 940us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 71ms/step - loss: 0.2570 - accuracy: 0.5291 - val_loss: 0.2497 - val_accuracy: 0.5429\nEpoch 2/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2400 - accuracy: 0.5979 - val_loss: 0.2400 - val_accuracy: 0.6190\nEpoch 3/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2321 - accuracy: 0.6190 - val_loss: 0.2458 - val_accuracy: 0.5619\nEpoch 4/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2251 - accuracy: 0.6519 - val_loss: 0.2489 - val_accuracy: 0.5524\nEpoch 5/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2194 - accuracy: 0.6688 - val_loss: 0.2396 - val_accuracy: 0.6381\nEpoch 6/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2153 - accuracy: 0.6762 - val_loss: 0.2337 - val_accuracy: 0.6381\nEpoch 7/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2097 - accuracy: 0.6899 - val_loss: 0.2352 - val_accuracy: 0.6381\nEpoch 8/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2060 - accuracy: 0.6984 - val_loss: 0.2497 - val_accuracy: 0.5429\nEpoch 9/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.2016 - accuracy: 0.7069 - val_loss: 0.2544 - val_accuracy: 0.5714\nEpoch 10/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1967 - accuracy: 0.7185 - val_loss: 0.2627 - val_accuracy: 0.5143\nEpoch 11/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1912 - accuracy: 0.7397 - val_loss: 0.2353 - val_accuracy: 0.6095\nEpoch 12/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1886 - accuracy: 0.7439 - val_loss: 0.2384 - val_accuracy: 0.6000\nEpoch 13/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1845 - accuracy: 0.7524 - val_loss: 0.2416 - val_accuracy: 0.6190\nEpoch 14/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1790 - accuracy: 0.7619 - val_loss: 0.2408 - val_accuracy: 0.6286\nEpoch 15/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1768 - accuracy: 0.7619 - val_loss: 0.2345 - val_accuracy: 0.6571\nEpoch 16/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1715 - accuracy: 0.7767 - val_loss: 0.2565 - val_accuracy: 0.6190\nEpoch 17/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1705 - accuracy: 0.7587 - val_loss: 0.2499 - val_accuracy: 0.6095\nEpoch 18/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1641 - accuracy: 0.7810 - val_loss: 0.2396 - val_accuracy: 0.6476\nEpoch 19/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1617 - accuracy: 0.7958 - val_loss: 0.2369 - val_accuracy: 0.6190\nEpoch 20/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1580 - accuracy: 0.7979 - val_loss: 0.2422 - val_accuracy: 0.6381\nEpoch 21/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1520 - accuracy: 0.8138 - val_loss: 0.2502 - val_accuracy: 0.6095\nEpoch 22/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1479 - accuracy: 0.8127 - val_loss: 0.2449 - val_accuracy: 0.6000\nEpoch 23/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1441 - accuracy: 0.8180 - val_loss: 0.2518 - val_accuracy: 0.5714\nEpoch 24/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1481 - accuracy: 0.8042 - val_loss: 0.2386 - val_accuracy: 0.6286\nEpoch 25/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1388 - accuracy: 0.8180 - val_loss: 0.2552 - val_accuracy: 0.6000\nEpoch 26/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1348 - accuracy: 0.8307 - val_loss: 0.2605 - val_accuracy: 0.5905\nEpoch 27/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1319 - accuracy: 0.8339 - val_loss: 0.2983 - val_accuracy: 0.5238\nEpoch 28/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1301 - accuracy: 0.8392 - val_loss: 0.2452 - val_accuracy: 0.6190\nEpoch 29/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1273 - accuracy: 0.8434 - val_loss: 0.2654 - val_accuracy: 0.6000\nEpoch 30/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1208 - accuracy: 0.8455 - val_loss: 0.2479 - val_accuracy: 0.6095\nHightest accuracy: 0.6571428775787354\n********** Test Fold 3 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_12\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_10 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_21 (Dense)            (None, 64)                2112      \n                                                                 \n dense_22 (Dense)            (None, 12)                780       \n                                                                 \n dense_23 (Dense)            (None, 64)                832       \n                                                                 \n dense_24 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_13\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_10 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_21 (Dense)            (None, 64)                2112      \n                                                                 \n dense_22 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_14\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_11 (InputLayer)       [(None, 12)]              0         \n                                                                 \n dense_23 (Dense)            (None, 64)                832       \n                                                                 \n dense_24 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 164s 1ms/step - loss: 0.2234 - accuracy: 0.4530 - val_loss: 0.2315 - val_accuracy: 0.4316\n226800/226800 [==============================] - 219s 963us/step\n25200/25200 [==============================] - 24s 960us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 72ms/step - loss: 0.2497 - accuracy: 0.5450 - val_loss: 0.2561 - val_accuracy: 0.5333\nEpoch 2/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2357 - accuracy: 0.5915 - val_loss: 0.2544 - val_accuracy: 0.5429\nEpoch 3/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.2277 - accuracy: 0.6169 - val_loss: 0.2480 - val_accuracy: 0.5429\nEpoch 4/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.2207 - accuracy: 0.6423 - val_loss: 0.2645 - val_accuracy: 0.5429\nEpoch 5/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.2185 - accuracy: 0.6455 - val_loss: 0.2557 - val_accuracy: 0.4857\nEpoch 6/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2120 - accuracy: 0.6720 - val_loss: 0.2515 - val_accuracy: 0.5143\nEpoch 7/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2088 - accuracy: 0.6772 - val_loss: 0.2535 - val_accuracy: 0.5333\nEpoch 8/30\n119/119 [==============================] - 8s 68ms/step - loss: 0.2026 - accuracy: 0.7132 - val_loss: 0.2570 - val_accuracy: 0.5048\nEpoch 9/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.2002 - accuracy: 0.7058 - val_loss: 0.2561 - val_accuracy: 0.5143\nEpoch 10/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1934 - accuracy: 0.7132 - val_loss: 0.2548 - val_accuracy: 0.5429\nEpoch 11/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1888 - accuracy: 0.7270 - val_loss: 0.2598 - val_accuracy: 0.5524\nEpoch 12/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1860 - accuracy: 0.7302 - val_loss: 0.2564 - val_accuracy: 0.5619\nEpoch 13/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1823 - accuracy: 0.7450 - val_loss: 0.2540 - val_accuracy: 0.5905\nEpoch 14/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1790 - accuracy: 0.7386 - val_loss: 0.2540 - val_accuracy: 0.5810\nEpoch 15/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1739 - accuracy: 0.7640 - val_loss: 0.2592 - val_accuracy: 0.5524\nEpoch 16/30\n119/119 [==============================] - 8s 68ms/step - loss: 0.1704 - accuracy: 0.7577 - val_loss: 0.2594 - val_accuracy: 0.5714\nEpoch 17/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1653 - accuracy: 0.7725 - val_loss: 0.2598 - val_accuracy: 0.5619\nEpoch 18/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1603 - accuracy: 0.7852 - val_loss: 0.2710 - val_accuracy: 0.4952\nEpoch 19/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1588 - accuracy: 0.7937 - val_loss: 0.2681 - val_accuracy: 0.5238\nEpoch 20/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1544 - accuracy: 0.7947 - val_loss: 0.2771 - val_accuracy: 0.5714\nEpoch 21/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1562 - accuracy: 0.7799 - val_loss: 0.2586 - val_accuracy: 0.5619\nEpoch 22/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1478 - accuracy: 0.7915 - val_loss: 0.2603 - val_accuracy: 0.5905\nEpoch 23/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1419 - accuracy: 0.8138 - val_loss: 0.2624 - val_accuracy: 0.5429\nEpoch 24/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1455 - accuracy: 0.8032 - val_loss: 0.2706 - val_accuracy: 0.6286\nEpoch 25/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1413 - accuracy: 0.8138 - val_loss: 0.2773 - val_accuracy: 0.5810\nEpoch 26/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1378 - accuracy: 0.8201 - val_loss: 0.2844 - val_accuracy: 0.5714\nEpoch 27/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1321 - accuracy: 0.8275 - val_loss: 0.2679 - val_accuracy: 0.5619\nEpoch 28/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1279 - accuracy: 0.8243 - val_loss: 0.2757 - val_accuracy: 0.5238\nEpoch 29/30\n119/119 [==============================] - 8s 67ms/step - loss: 0.1230 - accuracy: 0.8455 - val_loss: 0.2791 - val_accuracy: 0.5524\nEpoch 30/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1188 - accuracy: 0.8624 - val_loss: 0.2863 - val_accuracy: 0.4857\nHightest accuracy: 0.6285714507102966\n********** Test Fold 4 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_13 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_28 (Dense)            (None, 64)                2112      \n                                                                 \n dense_29 (Dense)            (None, 12)                780       \n                                                                 \n dense_30 (Dense)            (None, 64)                832       \n                                                                 \n dense_31 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_17\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_13 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_28 (Dense)            (None, 64)                2112      \n                                                                 \n dense_29 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_18\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_14 (InputLayer)       [(None, 12)]              0         \n                                                                 \n dense_30 (Dense)            (None, 64)                832       \n                                                                 \n dense_31 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 164s 1ms/step - loss: 0.2239 - accuracy: 0.4490 - val_loss: 0.2312 - val_accuracy: 0.4398\n226800/226800 [==============================] - 212s 936us/step\n25200/25200 [==============================] - 24s 955us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 11s 70ms/step - loss: 0.2551 - accuracy: 0.5228 - val_loss: 0.2551 - val_accuracy: 0.5714\nEpoch 2/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2371 - accuracy: 0.5968 - val_loss: 0.2520 - val_accuracy: 0.5619\nEpoch 3/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2275 - accuracy: 0.6370 - val_loss: 0.2494 - val_accuracy: 0.5429\nEpoch 4/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2198 - accuracy: 0.6635 - val_loss: 0.2536 - val_accuracy: 0.5714\nEpoch 5/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2144 - accuracy: 0.6836 - val_loss: 0.2656 - val_accuracy: 0.5048\nEpoch 6/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2077 - accuracy: 0.7026 - val_loss: 0.2564 - val_accuracy: 0.5619\nEpoch 7/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2019 - accuracy: 0.7122 - val_loss: 0.2573 - val_accuracy: 0.5143\nEpoch 8/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1962 - accuracy: 0.7206 - val_loss: 0.2443 - val_accuracy: 0.6190\nEpoch 9/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1913 - accuracy: 0.7429 - val_loss: 0.2604 - val_accuracy: 0.5143\nEpoch 10/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1863 - accuracy: 0.7471 - val_loss: 0.2542 - val_accuracy: 0.5333\nEpoch 11/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1811 - accuracy: 0.7481 - val_loss: 0.2487 - val_accuracy: 0.5714\nEpoch 12/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1777 - accuracy: 0.7503 - val_loss: 0.2573 - val_accuracy: 0.5619\nEpoch 13/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1733 - accuracy: 0.7693 - val_loss: 0.2571 - val_accuracy: 0.5333\nEpoch 14/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1668 - accuracy: 0.7735 - val_loss: 0.2607 - val_accuracy: 0.5810\nEpoch 15/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1611 - accuracy: 0.8000 - val_loss: 0.2883 - val_accuracy: 0.5238\nEpoch 16/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1618 - accuracy: 0.7778 - val_loss: 0.2656 - val_accuracy: 0.5810\nEpoch 17/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1522 - accuracy: 0.8053 - val_loss: 0.2602 - val_accuracy: 0.5714\nEpoch 18/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1447 - accuracy: 0.8148 - val_loss: 0.2593 - val_accuracy: 0.5714\nEpoch 19/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1414 - accuracy: 0.8169 - val_loss: 0.2810 - val_accuracy: 0.5619\nEpoch 20/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1392 - accuracy: 0.8169 - val_loss: 0.2608 - val_accuracy: 0.5810\nEpoch 21/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1330 - accuracy: 0.8370 - val_loss: 0.2639 - val_accuracy: 0.6095\nEpoch 22/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1306 - accuracy: 0.8370 - val_loss: 0.2596 - val_accuracy: 0.6095\nEpoch 23/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1262 - accuracy: 0.8444 - val_loss: 0.2650 - val_accuracy: 0.5905\nEpoch 24/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1230 - accuracy: 0.8529 - val_loss: 0.2534 - val_accuracy: 0.6190\nEpoch 25/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1153 - accuracy: 0.8571 - val_loss: 0.2752 - val_accuracy: 0.5714\nEpoch 26/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1150 - accuracy: 0.8688 - val_loss: 0.2700 - val_accuracy: 0.5714\nEpoch 27/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1092 - accuracy: 0.8804 - val_loss: 0.2741 - val_accuracy: 0.5429\nEpoch 28/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1054 - accuracy: 0.8847 - val_loss: 0.2733 - val_accuracy: 0.5810\nEpoch 29/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1004 - accuracy: 0.8857 - val_loss: 0.2481 - val_accuracy: 0.6667\nEpoch 30/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.0961 - accuracy: 0.8963 - val_loss: 0.2758 - val_accuracy: 0.6286\nHightest accuracy: 0.6666666865348816\n********** Test Fold 5 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_20\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_16 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_35 (Dense)            (None, 64)                2112      \n                                                                 \n dense_36 (Dense)            (None, 12)                780       \n                                                                 \n dense_37 (Dense)            (None, 64)                832       \n                                                                 \n dense_38 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_21\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_16 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_35 (Dense)            (None, 64)                2112      \n                                                                 \n dense_36 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_22\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_17 (InputLayer)       [(None, 12)]              0         \n                                                                 \n dense_37 (Dense)            (None, 64)                832       \n                                                                 \n dense_38 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 163s 1ms/step - loss: 0.2245 - accuracy: 0.4534 - val_loss: 0.2306 - val_accuracy: 0.4065\n226800/226800 [==============================] - 213s 939us/step\n25200/25200 [==============================] - 23s 927us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 68ms/step - loss: 0.2526 - accuracy: 0.5185 - val_loss: 0.2455 - val_accuracy: 0.5238\nEpoch 2/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2351 - accuracy: 0.6095 - val_loss: 0.2548 - val_accuracy: 0.5238\nEpoch 3/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2273 - accuracy: 0.6328 - val_loss: 0.2476 - val_accuracy: 0.5714\nEpoch 4/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.2201 - accuracy: 0.6476 - val_loss: 0.2492 - val_accuracy: 0.5524\nEpoch 5/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2154 - accuracy: 0.6741 - val_loss: 0.2587 - val_accuracy: 0.5333\nEpoch 6/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2085 - accuracy: 0.6984 - val_loss: 0.2569 - val_accuracy: 0.5333\nEpoch 7/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2042 - accuracy: 0.7005 - val_loss: 0.2528 - val_accuracy: 0.5524\nEpoch 8/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1988 - accuracy: 0.7132 - val_loss: 0.2661 - val_accuracy: 0.5333\nEpoch 9/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1972 - accuracy: 0.7153 - val_loss: 0.2670 - val_accuracy: 0.5714\nEpoch 10/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1917 - accuracy: 0.7249 - val_loss: 0.2598 - val_accuracy: 0.5619\nEpoch 11/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1862 - accuracy: 0.7439 - val_loss: 0.2515 - val_accuracy: 0.5714\nEpoch 12/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1821 - accuracy: 0.7608 - val_loss: 0.2782 - val_accuracy: 0.5429\nEpoch 13/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1776 - accuracy: 0.7524 - val_loss: 0.2749 - val_accuracy: 0.5619\nEpoch 14/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1734 - accuracy: 0.7651 - val_loss: 0.2637 - val_accuracy: 0.6095\nEpoch 15/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1691 - accuracy: 0.7746 - val_loss: 0.2696 - val_accuracy: 0.5619\nEpoch 16/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1627 - accuracy: 0.7767 - val_loss: 0.2535 - val_accuracy: 0.6095\nEpoch 17/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1614 - accuracy: 0.7683 - val_loss: 0.2555 - val_accuracy: 0.6000\nEpoch 18/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1587 - accuracy: 0.7926 - val_loss: 0.3062 - val_accuracy: 0.5143\nEpoch 19/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1539 - accuracy: 0.7989 - val_loss: 0.2962 - val_accuracy: 0.4571\nEpoch 20/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1480 - accuracy: 0.8169 - val_loss: 0.2449 - val_accuracy: 0.6381\nEpoch 21/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1450 - accuracy: 0.8116 - val_loss: 0.2642 - val_accuracy: 0.5619\nEpoch 22/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1439 - accuracy: 0.8106 - val_loss: 0.3031 - val_accuracy: 0.5048\nEpoch 23/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1393 - accuracy: 0.8265 - val_loss: 0.2759 - val_accuracy: 0.5143\nEpoch 24/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1340 - accuracy: 0.8370 - val_loss: 0.2668 - val_accuracy: 0.5810\nEpoch 25/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1325 - accuracy: 0.8265 - val_loss: 0.2690 - val_accuracy: 0.6095\nEpoch 26/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1335 - accuracy: 0.8275 - val_loss: 0.2736 - val_accuracy: 0.5905\nEpoch 27/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1283 - accuracy: 0.8487 - val_loss: 0.2718 - val_accuracy: 0.5905\nEpoch 28/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1221 - accuracy: 0.8487 - val_loss: 0.2573 - val_accuracy: 0.6286\nEpoch 29/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1184 - accuracy: 0.8646 - val_loss: 0.2825 - val_accuracy: 0.5524\nEpoch 30/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1139 - accuracy: 0.8614 - val_loss: 0.3014 - val_accuracy: 0.5619\nHightest accuracy: 0.6380952596664429\n********** Test Fold 6 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_24\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_19 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_42 (Dense)            (None, 64)                2112      \n                                                                 \n dense_43 (Dense)            (None, 12)                780       \n                                                                 \n dense_44 (Dense)            (None, 64)                832       \n                                                                 \n dense_45 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_25\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_19 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_42 (Dense)            (None, 64)                2112      \n                                                                 \n dense_43 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_26\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_20 (InputLayer)       [(None, 12)]              0         \n                                                                 \n dense_44 (Dense)            (None, 64)                832       \n                                                                 \n dense_45 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 160s 1ms/step - loss: 0.2264 - accuracy: 0.4464 - val_loss: 0.2171 - val_accuracy: 0.4683\n226800/226800 [==============================] - 214s 941us/step\n25200/25200 [==============================] - 23s 921us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 70ms/step - loss: 0.2503 - accuracy: 0.5513 - val_loss: 0.2477 - val_accuracy: 0.5524\nEpoch 2/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2359 - accuracy: 0.5989 - val_loss: 0.2483 - val_accuracy: 0.5143\nEpoch 3/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2275 - accuracy: 0.6497 - val_loss: 0.2521 - val_accuracy: 0.5524\nEpoch 4/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2210 - accuracy: 0.6519 - val_loss: 0.2557 - val_accuracy: 0.5238\nEpoch 5/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.2158 - accuracy: 0.6593 - val_loss: 0.2538 - val_accuracy: 0.5333\nEpoch 6/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2113 - accuracy: 0.6815 - val_loss: 0.2490 - val_accuracy: 0.5619\nEpoch 7/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.2071 - accuracy: 0.6910 - val_loss: 0.2515 - val_accuracy: 0.5524\nEpoch 8/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2022 - accuracy: 0.6974 - val_loss: 0.2523 - val_accuracy: 0.5524\nEpoch 9/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1996 - accuracy: 0.6952 - val_loss: 0.2589 - val_accuracy: 0.5429\nEpoch 10/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1960 - accuracy: 0.7175 - val_loss: 0.2569 - val_accuracy: 0.5238\nEpoch 11/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1902 - accuracy: 0.7153 - val_loss: 0.2567 - val_accuracy: 0.5429\nEpoch 12/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1872 - accuracy: 0.7249 - val_loss: 0.2628 - val_accuracy: 0.5524\nEpoch 13/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1842 - accuracy: 0.7376 - val_loss: 0.2633 - val_accuracy: 0.5238\nEpoch 14/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1778 - accuracy: 0.7344 - val_loss: 0.2700 - val_accuracy: 0.5333\nEpoch 15/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1754 - accuracy: 0.7492 - val_loss: 0.2604 - val_accuracy: 0.5524\nEpoch 16/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1696 - accuracy: 0.7683 - val_loss: 0.2689 - val_accuracy: 0.5333\nEpoch 17/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1673 - accuracy: 0.7693 - val_loss: 0.2632 - val_accuracy: 0.5714\nEpoch 18/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1648 - accuracy: 0.7820 - val_loss: 0.2610 - val_accuracy: 0.5429\nEpoch 19/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1608 - accuracy: 0.7778 - val_loss: 0.2764 - val_accuracy: 0.5429\nEpoch 20/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1553 - accuracy: 0.8011 - val_loss: 0.2857 - val_accuracy: 0.5619\nEpoch 21/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1546 - accuracy: 0.7894 - val_loss: 0.2744 - val_accuracy: 0.5714\nEpoch 22/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1482 - accuracy: 0.8074 - val_loss: 0.2700 - val_accuracy: 0.5810\nEpoch 23/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1456 - accuracy: 0.8032 - val_loss: 0.2704 - val_accuracy: 0.5619\nEpoch 24/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.1417 - accuracy: 0.8222 - val_loss: 0.2778 - val_accuracy: 0.5524\nEpoch 25/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1378 - accuracy: 0.8328 - val_loss: 0.2993 - val_accuracy: 0.4667\nEpoch 26/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1364 - accuracy: 0.8159 - val_loss: 0.2721 - val_accuracy: 0.5524\nEpoch 27/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1337 - accuracy: 0.8381 - val_loss: 0.2686 - val_accuracy: 0.5810\nEpoch 28/30\n119/119 [==============================] - 8s 65ms/step - loss: 0.1303 - accuracy: 0.8444 - val_loss: 0.2949 - val_accuracy: 0.5143\nEpoch 29/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1309 - accuracy: 0.8339 - val_loss: 0.2766 - val_accuracy: 0.5238\nEpoch 30/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1275 - accuracy: 0.8423 - val_loss: 0.2584 - val_accuracy: 0.5810\nHightest accuracy: 0.5809524059295654\n********** Test Fold 7 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_28\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_22 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_49 (Dense)            (None, 64)                2112      \n                                                                 \n dense_50 (Dense)            (None, 12)                780       \n                                                                 \n dense_51 (Dense)            (None, 64)                832       \n                                                                 \n dense_52 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_29\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_22 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_49 (Dense)            (None, 64)                2112      \n                                                                 \n dense_50 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_30\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_23 (InputLayer)       [(None, 12)]              0         \n                                                                 \n dense_51 (Dense)            (None, 64)                832       \n                                                                 \n dense_52 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 159s 1ms/step - loss: 0.2262 - accuracy: 0.4466 - val_loss: 0.2203 - val_accuracy: 0.4587\n226800/226800 [==============================] - 211s 928us/step\n25200/25200 [==============================] - 24s 938us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 66ms/step - loss: 0.2602 - accuracy: 0.5344 - val_loss: 0.2460 - val_accuracy: 0.5810\nEpoch 2/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.2408 - accuracy: 0.5841 - val_loss: 0.2511 - val_accuracy: 0.5524\nEpoch 3/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.2304 - accuracy: 0.6296 - val_loss: 0.2568 - val_accuracy: 0.4952\nEpoch 4/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.2240 - accuracy: 0.6593 - val_loss: 0.2497 - val_accuracy: 0.5905\nEpoch 5/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.2200 - accuracy: 0.6624 - val_loss: 0.2500 - val_accuracy: 0.5905\nEpoch 6/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.2122 - accuracy: 0.6677 - val_loss: 0.2584 - val_accuracy: 0.5810\nEpoch 7/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.2076 - accuracy: 0.6963 - val_loss: 0.2511 - val_accuracy: 0.5905\nEpoch 8/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.2012 - accuracy: 0.7069 - val_loss: 0.2581 - val_accuracy: 0.5714\nEpoch 9/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1980 - accuracy: 0.7122 - val_loss: 0.2568 - val_accuracy: 0.5905\nEpoch 10/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1923 - accuracy: 0.7291 - val_loss: 0.2593 - val_accuracy: 0.5905\nEpoch 11/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1886 - accuracy: 0.7280 - val_loss: 0.2613 - val_accuracy: 0.5619\nEpoch 12/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1856 - accuracy: 0.7407 - val_loss: 0.2664 - val_accuracy: 0.5333\nEpoch 13/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1808 - accuracy: 0.7376 - val_loss: 0.2654 - val_accuracy: 0.5524\nEpoch 14/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1751 - accuracy: 0.7503 - val_loss: 0.2665 - val_accuracy: 0.5619\nEpoch 15/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1718 - accuracy: 0.7587 - val_loss: 0.2700 - val_accuracy: 0.5810\nEpoch 16/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1664 - accuracy: 0.7683 - val_loss: 0.2711 - val_accuracy: 0.5524\nEpoch 17/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1648 - accuracy: 0.7735 - val_loss: 0.2627 - val_accuracy: 0.5524\nEpoch 18/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1640 - accuracy: 0.7704 - val_loss: 0.2673 - val_accuracy: 0.6095\nEpoch 19/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1610 - accuracy: 0.7799 - val_loss: 0.2611 - val_accuracy: 0.5429\nEpoch 20/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1559 - accuracy: 0.7894 - val_loss: 0.2679 - val_accuracy: 0.5714\nEpoch 21/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1519 - accuracy: 0.7937 - val_loss: 0.2702 - val_accuracy: 0.5429\nEpoch 22/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1474 - accuracy: 0.8053 - val_loss: 0.2646 - val_accuracy: 0.5810\nEpoch 23/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1445 - accuracy: 0.8085 - val_loss: 0.2597 - val_accuracy: 0.5333\nEpoch 24/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1418 - accuracy: 0.8169 - val_loss: 0.2621 - val_accuracy: 0.6000\nEpoch 25/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1393 - accuracy: 0.8307 - val_loss: 0.2568 - val_accuracy: 0.5429\nEpoch 26/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1327 - accuracy: 0.8360 - val_loss: 0.2559 - val_accuracy: 0.5905\nEpoch 27/30\n119/119 [==============================] - 7s 60ms/step - loss: 0.1316 - accuracy: 0.8307 - val_loss: 0.2733 - val_accuracy: 0.5714\nEpoch 28/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1279 - accuracy: 0.8233 - val_loss: 0.2758 - val_accuracy: 0.6000\nEpoch 29/30\n119/119 [==============================] - 7s 60ms/step - loss: 0.1277 - accuracy: 0.8317 - val_loss: 0.2703 - val_accuracy: 0.5429\nEpoch 30/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1189 - accuracy: 0.8667 - val_loss: 0.2807 - val_accuracy: 0.6000\nHightest accuracy: 0.6095238327980042\n********** Test Fold 8 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_32\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_25 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_56 (Dense)            (None, 64)                2112      \n                                                                 \n dense_57 (Dense)            (None, 12)                780       \n                                                                 \n dense_58 (Dense)            (None, 64)                832       \n                                                                 \n dense_59 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_33\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_25 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_56 (Dense)            (None, 64)                2112      \n                                                                 \n dense_57 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_34\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_26 (InputLayer)       [(None, 12)]              0         \n                                                                 \n dense_58 (Dense)            (None, 64)                832       \n                                                                 \n dense_59 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 159s 1ms/step - loss: 0.2251 - accuracy: 0.4500 - val_loss: 0.2296 - val_accuracy: 0.4426\n226800/226800 [==============================] - 210s 925us/step\n25200/25200 [==============================] - 23s 918us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 67ms/step - loss: 0.2558 - accuracy: 0.5249 - val_loss: 0.2392 - val_accuracy: 0.5619\nEpoch 2/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.2406 - accuracy: 0.5757 - val_loss: 0.2493 - val_accuracy: 0.5714\nEpoch 3/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.2300 - accuracy: 0.6243 - val_loss: 0.2559 - val_accuracy: 0.5048\nEpoch 4/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.2263 - accuracy: 0.6296 - val_loss: 0.2505 - val_accuracy: 0.5524\nEpoch 5/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.2209 - accuracy: 0.6624 - val_loss: 0.2541 - val_accuracy: 0.5619\nEpoch 6/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.2162 - accuracy: 0.6646 - val_loss: 0.2487 - val_accuracy: 0.5714\nEpoch 7/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.2122 - accuracy: 0.6741 - val_loss: 0.2456 - val_accuracy: 0.5905\nEpoch 8/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.2067 - accuracy: 0.6868 - val_loss: 0.2493 - val_accuracy: 0.6000\nEpoch 9/30\n119/119 [==============================] - 7s 60ms/step - loss: 0.2022 - accuracy: 0.6952 - val_loss: 0.2484 - val_accuracy: 0.6000\nEpoch 10/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1972 - accuracy: 0.7122 - val_loss: 0.2496 - val_accuracy: 0.5810\nEpoch 11/30\n119/119 [==============================] - 7s 60ms/step - loss: 0.1934 - accuracy: 0.7280 - val_loss: 0.2402 - val_accuracy: 0.6000\nEpoch 12/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1904 - accuracy: 0.7206 - val_loss: 0.2377 - val_accuracy: 0.6381\nEpoch 13/30\n119/119 [==============================] - 7s 60ms/step - loss: 0.1856 - accuracy: 0.7450 - val_loss: 0.2412 - val_accuracy: 0.6286\nEpoch 14/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1810 - accuracy: 0.7545 - val_loss: 0.2689 - val_accuracy: 0.5619\nEpoch 15/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1779 - accuracy: 0.7651 - val_loss: 0.2237 - val_accuracy: 0.6762\nEpoch 16/30\n119/119 [==============================] - 7s 60ms/step - loss: 0.1709 - accuracy: 0.7725 - val_loss: 0.2316 - val_accuracy: 0.6381\nEpoch 17/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1660 - accuracy: 0.7746 - val_loss: 0.2659 - val_accuracy: 0.5143\nEpoch 18/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1622 - accuracy: 0.7926 - val_loss: 0.2379 - val_accuracy: 0.6190\nEpoch 19/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1620 - accuracy: 0.7831 - val_loss: 0.2334 - val_accuracy: 0.6000\nEpoch 20/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1580 - accuracy: 0.7905 - val_loss: 0.2360 - val_accuracy: 0.6381\nEpoch 21/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1527 - accuracy: 0.7979 - val_loss: 0.2369 - val_accuracy: 0.6476\nEpoch 22/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1494 - accuracy: 0.8127 - val_loss: 0.2860 - val_accuracy: 0.5048\nEpoch 23/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1474 - accuracy: 0.8063 - val_loss: 0.2376 - val_accuracy: 0.6190\nEpoch 24/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1405 - accuracy: 0.8233 - val_loss: 0.2637 - val_accuracy: 0.5714\nEpoch 25/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1349 - accuracy: 0.8296 - val_loss: 0.2503 - val_accuracy: 0.5905\nEpoch 26/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1290 - accuracy: 0.8413 - val_loss: 0.2726 - val_accuracy: 0.5714\nEpoch 27/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1289 - accuracy: 0.8413 - val_loss: 0.2430 - val_accuracy: 0.6381\nEpoch 28/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1257 - accuracy: 0.8349 - val_loss: 0.2838 - val_accuracy: 0.5810\nEpoch 29/30\n119/119 [==============================] - 8s 66ms/step - loss: 0.1255 - accuracy: 0.8434 - val_loss: 0.2526 - val_accuracy: 0.5905\nEpoch 30/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1227 - accuracy: 0.8413 - val_loss: 0.2264 - val_accuracy: 0.6667\nHightest accuracy: 0.6761904954910278\n********** Test Fold 9 ************\n(945, 32, 7680) (105, 32, 7680)\n(7257600, 32) (806400, 32)\nModel: \"model_36\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_28 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_63 (Dense)            (None, 64)                2112      \n                                                                 \n dense_64 (Dense)            (None, 12)                780       \n                                                                 \n dense_65 (Dense)            (None, 64)                832       \n                                                                 \n dense_66 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_37\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_28 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_63 (Dense)            (None, 64)                2112      \n                                                                 \n dense_64 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_38\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_29 (InputLayer)       [(None, 12)]              0         \n                                                                 \n dense_65 (Dense)            (None, 64)                832       \n                                                                 \n dense_66 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n113400/113400 [==============================] - 163s 1ms/step - loss: 0.2253 - accuracy: 0.4451 - val_loss: 0.2246 - val_accuracy: 0.4656\n226800/226800 [==============================] - 212s 934us/step\n25200/25200 [==============================] - 23s 929us/step\nEncoded training data shape:  (945, 12, 7680)\nEncoded test data shape:  (105, 12, 7680)\nAll features of training data shape:  (945, 119, 48)\nAll features of test data shape:  (105, 119, 48)\nEpoch 1/30\n119/119 [==============================] - 10s 68ms/step - loss: 0.2574 - accuracy: 0.5291 - val_loss: 0.2534 - val_accuracy: 0.5238\nEpoch 2/30\n119/119 [==============================] - 8s 64ms/step - loss: 0.2389 - accuracy: 0.5884 - val_loss: 0.2538 - val_accuracy: 0.5619\nEpoch 3/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2332 - accuracy: 0.6063 - val_loss: 0.2496 - val_accuracy: 0.5714\nEpoch 4/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.2268 - accuracy: 0.6434 - val_loss: 0.2473 - val_accuracy: 0.5714\nEpoch 5/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2219 - accuracy: 0.6444 - val_loss: 0.2470 - val_accuracy: 0.5619\nEpoch 6/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2171 - accuracy: 0.6720 - val_loss: 0.2442 - val_accuracy: 0.5524\nEpoch 7/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.2134 - accuracy: 0.6688 - val_loss: 0.2459 - val_accuracy: 0.6095\nEpoch 8/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.2126 - accuracy: 0.6815 - val_loss: 0.2457 - val_accuracy: 0.5524\nEpoch 9/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.2067 - accuracy: 0.6984 - val_loss: 0.2396 - val_accuracy: 0.5810\nEpoch 10/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.2025 - accuracy: 0.6974 - val_loss: 0.2408 - val_accuracy: 0.5905\nEpoch 11/30\n119/119 [==============================] - 8s 63ms/step - loss: 0.1969 - accuracy: 0.7249 - val_loss: 0.2413 - val_accuracy: 0.5810\nEpoch 12/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1928 - accuracy: 0.7302 - val_loss: 0.2441 - val_accuracy: 0.6000\nEpoch 13/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1895 - accuracy: 0.7196 - val_loss: 0.2459 - val_accuracy: 0.5714\nEpoch 14/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1865 - accuracy: 0.7471 - val_loss: 0.2506 - val_accuracy: 0.5619\nEpoch 15/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1819 - accuracy: 0.7503 - val_loss: 0.2532 - val_accuracy: 0.5619\nEpoch 16/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1780 - accuracy: 0.7471 - val_loss: 0.2589 - val_accuracy: 0.5714\nEpoch 17/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1729 - accuracy: 0.7672 - val_loss: 0.2506 - val_accuracy: 0.5905\nEpoch 18/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1696 - accuracy: 0.7704 - val_loss: 0.2418 - val_accuracy: 0.5714\nEpoch 19/30\n119/119 [==============================] - 7s 63ms/step - loss: 0.1636 - accuracy: 0.7831 - val_loss: 0.2403 - val_accuracy: 0.5905\nEpoch 20/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1607 - accuracy: 0.7989 - val_loss: 0.2429 - val_accuracy: 0.5905\nEpoch 21/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1577 - accuracy: 0.7915 - val_loss: 0.2461 - val_accuracy: 0.5905\nEpoch 22/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1525 - accuracy: 0.8011 - val_loss: 0.2496 - val_accuracy: 0.6000\nEpoch 23/30\n119/119 [==============================] - 7s 60ms/step - loss: 0.1474 - accuracy: 0.8201 - val_loss: 0.2500 - val_accuracy: 0.5714\nEpoch 24/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1449 - accuracy: 0.8085 - val_loss: 0.2333 - val_accuracy: 0.6190\nEpoch 25/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1413 - accuracy: 0.8116 - val_loss: 0.2601 - val_accuracy: 0.6000\nEpoch 26/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1395 - accuracy: 0.8296 - val_loss: 0.2478 - val_accuracy: 0.6190\nEpoch 27/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1307 - accuracy: 0.8444 - val_loss: 0.2552 - val_accuracy: 0.5714\nEpoch 28/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1279 - accuracy: 0.8392 - val_loss: 0.2566 - val_accuracy: 0.5905\nEpoch 29/30\n119/119 [==============================] - 7s 62ms/step - loss: 0.1246 - accuracy: 0.8540 - val_loss: 0.2687 - val_accuracy: 0.5333\nEpoch 30/30\n119/119 [==============================] - 7s 61ms/step - loss: 0.1268 - accuracy: 0.8392 - val_loss: 0.2405 - val_accuracy: 0.6000\nHightest accuracy: 0.6190476417541504\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# **Full data training on one model**","metadata":{}},{"cell_type":"markdown","source":"## **Valence Model**","metadata":{}},{"cell_type":"code","source":"all_labels, all_data = load_np_data(dimension=\"valence\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:38:58.342692Z","iopub.execute_input":"2024-11-28T13:38:58.343086Z","iopub.status.idle":"2024-11-28T13:38:59.168190Z","shell.execute_reply.started":"2024-11-28T13:38:58.343044Z","shell.execute_reply":"2024-11-28T13:38:59.167356Z"}},"outputs":[{"name":"stdout","text":"Total valence:  (1059,) (1059, 32, 7680)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"### **Tranformers**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Shuffle and prepare all data\nall_data, all_labels = shuffle(all_data, all_labels, random_state=0)\nprint(all_data.shape, all_labels.shape)\n\n# Transform all data to vector form\nall_vectors = vector_transform(all_data)\nprint(all_vectors.shape)\n\n# -------- Create new autoencoder --------\ninput_layer = Input(shape=(32,))\nencoded = Dense(64, activation=None)(input_layer)\nbottleneck_layer = Dense(bottleneck, activation=None)(encoded)\ndecoded = Dense(64, activation=None)(bottleneck_layer)\ndecoded = Dense(32, activation=None)(decoded)\nautoencoder = Model(input_layer, decoded)\nautoencoder.summary()\n\nencoder = Model(input_layer, bottleneck_layer)\nencoder.summary()\n\ndecoder_input_layer = Input(shape=(bottleneck,))\ndecoder_layer = autoencoder.layers[-2](decoder_input_layer)\ndecoder_layer = autoencoder.layers[-1](decoder_layer)\ndecoder = Model(decoder_input_layer, decoder_layer)\ndecoder.summary()\n\n# -------- Compile and train autoencoder --------\nautoencoder.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\nautoencoder.fit(all_vectors, all_vectors, epochs=1, batch_size=64, shuffle=True, validation_split=0.1)\nautoencoder.save(\"/kaggle/working/Results/autoencoder_model/autoencoder_model_arousal.h5\")\n\n# -------- Encode all data --------\nall_data_encoded = encoder.predict(all_vectors)\nall_data_encoded = inverse_vector_transform(all_data_encoded)\nprint(\"Encoded data shape: \", all_data_encoded.shape)\n\n# -------- Feature extraction from 12 source signals --------\nall_band_power = []\nfor data in all_data_encoded:  # For every trial\n    with io.capture_output() as captured:\n        trial_band_power = trial_psd_extraction_integration(data)\n    all_band_power.append(trial_band_power)\nall_band_power = np.array(all_band_power)\nprint(\"All features shape: \", all_band_power.shape)\n\n# -------- Train-test split --------\ntrain_data, test_data, train_labels, test_labels = train_test_split(all_band_power, all_labels, test_size=0.1, random_state=42)\nprint(train_data.shape, test_data.shape)\n\n# -------- Create Transformer model --------\ndef transformer_encoder(inputs, num_heads, ff_dim, dropout_rate):\n    # Multi-head Self-Attention\n    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n    attention_output = Dropout(dropout_rate)(attention_output)\n    # Add & Normalize\n    attention_output = LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n\n    # Feed-Forward Network\n    ff_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n    ff_output = Dense(inputs.shape[-1])(ff_output)\n    ff_output = Dropout(dropout_rate)(ff_output)\n\n    # Add & Normalize\n    return LayerNormalization(epsilon=1e-6)(attention_output + ff_output)\n\n# Input to the Transformer\ninputs = Input(shape=(train_data.shape[1], train_data.shape[2]))\n\n# Transformer block\nx = transformer_encoder(inputs, num_heads=4, ff_dim=128, dropout_rate=0.1)\nx = GlobalAveragePooling1D()(x)  # Pooling to reduce sequence dimension\nx = Dense(64, activation=\"relu\")(x)\noutput = Dense(1, activation=\"sigmoid\")(x)\n\n# Model definition\ntransformer_model = Model(inputs, output)\ntransformer_model.summary()\n\n# -------- Compile and train Transformer model --------\ntransformer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = transformer_model.fit(\n    train_data, train_labels, \n    epochs=30, \n    batch_size=16, \n    validation_data=(test_data, test_labels)\n)\nprint(\"Highest accuracy: \" + str(max(history.history['val_accuracy'])))\ntransformer_model.save(\"/kaggle/working/Results/Transformer_model/Transformer_model_arousal.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:39:18.603148Z","iopub.execute_input":"2024-11-28T13:39:18.603858Z","iopub.status.idle":"2024-11-28T13:49:48.645897Z","shell.execute_reply.started":"2024-11-28T13:39:18.603820Z","shell.execute_reply":"2024-11-28T13:49:48.644979Z"}},"outputs":[{"name":"stdout","text":"(1059, 32, 7680) (1059,)\n(8133120, 32)\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 32)]              0         \n                                                                 \n dense (Dense)               (None, 64)                2112      \n                                                                 \n dense_1 (Dense)             (None, 12)                780       \n                                                                 \n dense_2 (Dense)             (None, 64)                832       \n                                                                 \n dense_3 (Dense)             (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 32)]              0         \n                                                                 \n dense (Dense)               (None, 64)                2112      \n                                                                 \n dense_1 (Dense)             (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 12)]              0         \n                                                                 \n dense_2 (Dense)             (None, 64)                832       \n                                                                 \n dense_3 (Dense)             (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n114372/114372 [==============================] - 159s 1ms/step - loss: 0.2254 - accuracy: 0.4461 - val_loss: 0.2212 - val_accuracy: 0.4819\n254160/254160 [==============================] - 231s 910us/step\nEncoded data shape:  (1059, 12, 7680)\nAll features shape:  (1059, 119, 48)\n(953, 119, 48) (106, 119, 48)\nModel: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None, 119, 48)]    0           []                               \n                                                                                                  \n multi_head_attention (MultiHea  (None, 119, 48)     37488       ['input_3[0][0]',                \n dAttention)                                                      'input_3[0][0]']                \n                                                                                                  \n dropout (Dropout)              (None, 119, 48)      0           ['multi_head_attention[0][0]']   \n                                                                                                  \n tf.__operators__.add (TFOpLamb  (None, 119, 48)     0           ['input_3[0][0]',                \n da)                                                              'dropout[0][0]']                \n                                                                                                  \n layer_normalization (LayerNorm  (None, 119, 48)     96          ['tf.__operators__.add[0][0]']   \n alization)                                                                                       \n                                                                                                  \n dense_4 (Dense)                (None, 119, 128)     6272        ['layer_normalization[0][0]']    \n                                                                                                  \n dense_5 (Dense)                (None, 119, 48)      6192        ['dense_4[0][0]']                \n                                                                                                  \n dropout_1 (Dropout)            (None, 119, 48)      0           ['dense_5[0][0]']                \n                                                                                                  \n tf.__operators__.add_1 (TFOpLa  (None, 119, 48)     0           ['layer_normalization[0][0]',    \n mbda)                                                            'dropout_1[0][0]']              \n                                                                                                  \n layer_normalization_1 (LayerNo  (None, 119, 48)     96          ['tf.__operators__.add_1[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n global_average_pooling1d (Glob  (None, 48)          0           ['layer_normalization_1[0][0]']  \n alAveragePooling1D)                                                                              \n                                                                                                  \n dense_6 (Dense)                (None, 64)           3136        ['global_average_pooling1d[0][0]'\n                                                                 ]                                \n                                                                                                  \n dense_7 (Dense)                (None, 1)            65          ['dense_6[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 53,345\nTrainable params: 53,345\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/30\n60/60 [==============================] - 4s 41ms/step - loss: 0.6982 - accuracy: 0.5519 - val_loss: 0.7322 - val_accuracy: 0.5000\nEpoch 2/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.6816 - accuracy: 0.5645 - val_loss: 0.7145 - val_accuracy: 0.5472\nEpoch 3/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.6657 - accuracy: 0.5845 - val_loss: 0.7150 - val_accuracy: 0.5283\nEpoch 4/30\n60/60 [==============================] - 2s 35ms/step - loss: 0.6606 - accuracy: 0.5981 - val_loss: 0.6670 - val_accuracy: 0.6038\nEpoch 5/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.6714 - accuracy: 0.5876 - val_loss: 0.6815 - val_accuracy: 0.5283\nEpoch 6/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.6627 - accuracy: 0.5876 - val_loss: 0.6933 - val_accuracy: 0.5566\nEpoch 7/30\n60/60 [==============================] - 2s 39ms/step - loss: 0.6324 - accuracy: 0.6359 - val_loss: 0.6969 - val_accuracy: 0.5849\nEpoch 8/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.6286 - accuracy: 0.6180 - val_loss: 0.7202 - val_accuracy: 0.5566\nEpoch 9/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.6187 - accuracy: 0.6474 - val_loss: 0.7126 - val_accuracy: 0.5283\nEpoch 10/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.6006 - accuracy: 0.6611 - val_loss: 0.7270 - val_accuracy: 0.5755\nEpoch 11/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.5881 - accuracy: 0.6789 - val_loss: 0.7256 - val_accuracy: 0.5755\nEpoch 12/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.5803 - accuracy: 0.6873 - val_loss: 0.7575 - val_accuracy: 0.5755\nEpoch 13/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.5655 - accuracy: 0.7041 - val_loss: 0.7827 - val_accuracy: 0.5377\nEpoch 14/30\n60/60 [==============================] - 2s 35ms/step - loss: 0.5476 - accuracy: 0.6978 - val_loss: 0.8901 - val_accuracy: 0.5283\nEpoch 15/30\n60/60 [==============================] - 2s 33ms/step - loss: 0.5687 - accuracy: 0.6999 - val_loss: 0.7266 - val_accuracy: 0.6226\nEpoch 16/30\n60/60 [==============================] - 2s 33ms/step - loss: 0.5207 - accuracy: 0.7156 - val_loss: 0.7323 - val_accuracy: 0.6038\nEpoch 17/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.5358 - accuracy: 0.7188 - val_loss: 0.7352 - val_accuracy: 0.6132\nEpoch 18/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.5239 - accuracy: 0.7167 - val_loss: 0.7077 - val_accuracy: 0.6321\nEpoch 19/30\n60/60 [==============================] - 2s 35ms/step - loss: 0.5178 - accuracy: 0.7240 - val_loss: 0.6849 - val_accuracy: 0.6321\nEpoch 20/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.4809 - accuracy: 0.7408 - val_loss: 0.7962 - val_accuracy: 0.5755\nEpoch 21/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.4699 - accuracy: 0.7608 - val_loss: 0.7901 - val_accuracy: 0.6038\nEpoch 22/30\n60/60 [==============================] - 2s 35ms/step - loss: 0.4824 - accuracy: 0.7471 - val_loss: 0.8293 - val_accuracy: 0.5660\nEpoch 23/30\n60/60 [==============================] - 2s 38ms/step - loss: 0.4908 - accuracy: 0.7524 - val_loss: 0.7349 - val_accuracy: 0.5943\nEpoch 24/30\n60/60 [==============================] - 2s 33ms/step - loss: 0.4719 - accuracy: 0.7534 - val_loss: 0.8295 - val_accuracy: 0.5755\nEpoch 25/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.4397 - accuracy: 0.7828 - val_loss: 0.9148 - val_accuracy: 0.5755\nEpoch 26/30\n60/60 [==============================] - 2s 33ms/step - loss: 0.4335 - accuracy: 0.7775 - val_loss: 0.7250 - val_accuracy: 0.6415\nEpoch 27/30\n60/60 [==============================] - 2s 35ms/step - loss: 0.4641 - accuracy: 0.7671 - val_loss: 0.8424 - val_accuracy: 0.6321\nEpoch 28/30\n60/60 [==============================] - 2s 35ms/step - loss: 0.4160 - accuracy: 0.7985 - val_loss: 0.7309 - val_accuracy: 0.6226\nEpoch 29/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.4153 - accuracy: 0.7996 - val_loss: 0.9186 - val_accuracy: 0.5755\nEpoch 30/30\n60/60 [==============================] - 2s 34ms/step - loss: 0.3925 - accuracy: 0.7985 - val_loss: 0.9215 - val_accuracy: 0.6226\nHighest accuracy: 0.6415094137191772\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"### **Transformer + LSTM**","metadata":{}},{"cell_type":"code","source":"inputs = Input(shape=(train_data.shape[1], train_data.shape[2]))\nx = LSTM(64, return_sequences=True)(inputs)\nx = transformer_encoder(x, num_heads=4, ff_dim=128, dropout_rate=0.1)\nx = GlobalAveragePooling1D()(x)\nx = Dense(64, activation=\"relu\")(x)\noutput = Dense(1, activation=\"sigmoid\")(x)\nhybrid_model = Model(inputs, output)\n\nhybrid_model.summary()\n\n# -------- Compile and train Transformer model --------\nhybrid_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = hybrid_model.fit(\n    train_data, train_labels, \n    epochs=30, \n    batch_size=16, \n    validation_data=(test_data, test_labels)\n)\nprint(\"Highest accuracy: \" + str(max(history.history['val_accuracy'])))\nhybrid_model.save(\"/kaggle/working/Results/Transformer_model/Transformer_hybrid_model_arousal.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:53:13.986687Z","iopub.execute_input":"2024-11-28T13:53:13.987189Z","iopub.status.idle":"2024-11-28T13:55:59.722934Z","shell.execute_reply.started":"2024-11-28T13:53:13.987135Z","shell.execute_reply":"2024-11-28T13:55:59.721941Z"}},"outputs":[{"name":"stdout","text":"Model: \"model_8\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_7 (InputLayer)           [(None, 119, 48)]    0           []                               \n                                                                                                  \n lstm_1 (LSTM)                  (None, 119, 64)      28928       ['input_7[0][0]']                \n                                                                                                  \n multi_head_attention_2 (MultiH  (None, 119, 64)     66368       ['lstm_1[0][0]',                 \n eadAttention)                                                    'lstm_1[0][0]']                 \n                                                                                                  \n dropout_4 (Dropout)            (None, 119, 64)      0           ['multi_head_attention_2[0][0]'] \n                                                                                                  \n tf.__operators__.add_4 (TFOpLa  (None, 119, 64)     0           ['lstm_1[0][0]',                 \n mbda)                                                            'dropout_4[0][0]']              \n                                                                                                  \n layer_normalization_4 (LayerNo  (None, 119, 64)     128         ['tf.__operators__.add_4[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n dense_16 (Dense)               (None, 119, 128)     8320        ['layer_normalization_4[0][0]']  \n                                                                                                  \n dense_17 (Dense)               (None, 119, 64)      8256        ['dense_16[0][0]']               \n                                                                                                  \n dropout_5 (Dropout)            (None, 119, 64)      0           ['dense_17[0][0]']               \n                                                                                                  \n tf.__operators__.add_5 (TFOpLa  (None, 119, 64)     0           ['layer_normalization_4[0][0]',  \n mbda)                                                            'dropout_5[0][0]']              \n                                                                                                  \n layer_normalization_5 (LayerNo  (None, 119, 64)     128         ['tf.__operators__.add_5[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n global_average_pooling1d_2 (Gl  (None, 64)          0           ['layer_normalization_5[0][0]']  \n obalAveragePooling1D)                                                                            \n                                                                                                  \n dense_18 (Dense)               (None, 64)           4160        ['global_average_pooling1d_2[0][0\n                                                                 ]']                              \n                                                                                                  \n dense_19 (Dense)               (None, 1)            65          ['dense_18[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 116,353\nTrainable params: 116,353\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/30\n60/60 [==============================] - 9s 98ms/step - loss: 0.7173 - accuracy: 0.5247 - val_loss: 0.6903 - val_accuracy: 0.5377\nEpoch 2/30\n60/60 [==============================] - 5s 91ms/step - loss: 0.6686 - accuracy: 0.5960 - val_loss: 0.6737 - val_accuracy: 0.5283\nEpoch 3/30\n60/60 [==============================] - 5s 89ms/step - loss: 0.6588 - accuracy: 0.5887 - val_loss: 0.6995 - val_accuracy: 0.4811\nEpoch 4/30\n60/60 [==============================] - 5s 90ms/step - loss: 0.6574 - accuracy: 0.6159 - val_loss: 0.7057 - val_accuracy: 0.5566\nEpoch 5/30\n60/60 [==============================] - 5s 91ms/step - loss: 0.6429 - accuracy: 0.6233 - val_loss: 0.6944 - val_accuracy: 0.5566\nEpoch 6/30\n60/60 [==============================] - 6s 93ms/step - loss: 0.6296 - accuracy: 0.6317 - val_loss: 0.7048 - val_accuracy: 0.5094\nEpoch 7/30\n60/60 [==============================] - 5s 90ms/step - loss: 0.6428 - accuracy: 0.5866 - val_loss: 0.6915 - val_accuracy: 0.5755\nEpoch 8/30\n60/60 [==============================] - 5s 87ms/step - loss: 0.6241 - accuracy: 0.6369 - val_loss: 0.6689 - val_accuracy: 0.5283\nEpoch 9/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.6263 - accuracy: 0.6327 - val_loss: 0.6621 - val_accuracy: 0.6132\nEpoch 10/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.5936 - accuracy: 0.6758 - val_loss: 0.6921 - val_accuracy: 0.6132\nEpoch 11/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.5836 - accuracy: 0.6758 - val_loss: 0.7007 - val_accuracy: 0.6132\nEpoch 12/30\n60/60 [==============================] - 6s 93ms/step - loss: 0.5686 - accuracy: 0.6999 - val_loss: 0.6940 - val_accuracy: 0.6038\nEpoch 13/30\n60/60 [==============================] - 5s 89ms/step - loss: 0.5586 - accuracy: 0.6967 - val_loss: 0.7104 - val_accuracy: 0.6132\nEpoch 14/30\n60/60 [==============================] - 5s 87ms/step - loss: 0.5479 - accuracy: 0.6946 - val_loss: 0.7930 - val_accuracy: 0.5660\nEpoch 15/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.5270 - accuracy: 0.7230 - val_loss: 0.7965 - val_accuracy: 0.6415\nEpoch 16/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.5515 - accuracy: 0.7062 - val_loss: 0.7855 - val_accuracy: 0.5755\nEpoch 17/30\n60/60 [==============================] - 5s 90ms/step - loss: 0.5143 - accuracy: 0.7419 - val_loss: 0.8505 - val_accuracy: 0.6321\nEpoch 18/30\n60/60 [==============================] - 6s 95ms/step - loss: 0.5025 - accuracy: 0.7314 - val_loss: 0.7460 - val_accuracy: 0.5943\nEpoch 19/30\n60/60 [==============================] - 5s 90ms/step - loss: 0.4728 - accuracy: 0.7723 - val_loss: 0.9078 - val_accuracy: 0.6132\nEpoch 20/30\n60/60 [==============================] - 5s 89ms/step - loss: 0.4667 - accuracy: 0.7681 - val_loss: 0.9182 - val_accuracy: 0.5755\nEpoch 21/30\n60/60 [==============================] - 5s 89ms/step - loss: 0.4441 - accuracy: 0.7880 - val_loss: 1.0135 - val_accuracy: 0.5660\nEpoch 22/30\n60/60 [==============================] - 5s 89ms/step - loss: 0.4485 - accuracy: 0.7692 - val_loss: 0.9305 - val_accuracy: 0.5283\nEpoch 23/30\n60/60 [==============================] - 5s 89ms/step - loss: 0.4715 - accuracy: 0.7566 - val_loss: 0.9588 - val_accuracy: 0.5849\nEpoch 24/30\n60/60 [==============================] - 6s 95ms/step - loss: 0.4210 - accuracy: 0.8111 - val_loss: 1.0157 - val_accuracy: 0.5755\nEpoch 25/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.4055 - accuracy: 0.7964 - val_loss: 1.0035 - val_accuracy: 0.6038\nEpoch 26/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.4324 - accuracy: 0.7964 - val_loss: 0.9156 - val_accuracy: 0.5566\nEpoch 27/30\n60/60 [==============================] - 5s 87ms/step - loss: 0.3819 - accuracy: 0.8237 - val_loss: 0.8235 - val_accuracy: 0.6981\nEpoch 28/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.3686 - accuracy: 0.8216 - val_loss: 0.9202 - val_accuracy: 0.5660\nEpoch 29/30\n60/60 [==============================] - 5s 88ms/step - loss: 0.3486 - accuracy: 0.8468 - val_loss: 0.8547 - val_accuracy: 0.6226\nEpoch 30/30\n60/60 [==============================] - 6s 95ms/step - loss: 0.3533 - accuracy: 0.8426 - val_loss: 1.1225 - val_accuracy: 0.5943\nHighest accuracy: 0.698113203048706\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import tensorflow as tf\n\ndef positional_encoding(sequence_length, model_dim):\n    position = np.arange(sequence_length)[:, np.newaxis]\n    div_term = np.exp(np.arange(0, model_dim, 2) * -(np.log(10000.0) / model_dim))\n    pos_encoding = np.zeros((sequence_length, model_dim))\n    pos_encoding[:, 0::2] = np.sin(position * div_term)\n    pos_encoding[:, 1::2] = np.cos(position * div_term)\n    return tf.constant(pos_encoding, dtype=tf.float32)\n\n# Apply positional encoding\ninputs = Input(shape=(train_data.shape[1], train_data.shape[2]))\npos_encoding = positional_encoding(train_data.shape[1], train_data.shape[2])\nx = inputs + pos_encoding\nx = LSTM(64, return_sequences=True)(inputs)\nx = transformer_encoder(x, num_heads=4, ff_dim=128, dropout_rate=0.1)\nx = GlobalAveragePooling1D()(x)\nx = Dense(64, activation=\"relu\")(x)\noutput = Dense(1, activation=\"sigmoid\")(x)\nhybrid_model = Model(inputs, output)\n\nhybrid_model.summary()\n\n# -------- Compile and train Transformer model --------\nhybrid_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = hybrid_model.fit(\n    train_data, train_labels, \n    epochs=30, \n    batch_size=32, \n    validation_data=(test_data, test_labels)\n)\nprint(\"Highest accuracy: \" + str(max(history.history['val_accuracy'])))\nhybrid_model.save(\"/kaggle/working/Results/Transformer_model/Transformer_hybrid_model_arousal.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T13:59:27.527699Z","iopub.execute_input":"2024-11-28T13:59:27.528315Z","iopub.status.idle":"2024-11-28T14:01:27.222855Z","shell.execute_reply.started":"2024-11-28T13:59:27.528281Z","shell.execute_reply":"2024-11-28T14:01:27.221926Z"}},"outputs":[{"name":"stdout","text":"Model: \"model_10\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_10 (InputLayer)          [(None, 119, 48)]    0           []                               \n                                                                                                  \n lstm_3 (LSTM)                  (None, 119, 64)      28928       ['input_10[0][0]']               \n                                                                                                  \n multi_head_attention_4 (MultiH  (None, 119, 64)     66368       ['lstm_3[0][0]',                 \n eadAttention)                                                    'lstm_3[0][0]']                 \n                                                                                                  \n dropout_8 (Dropout)            (None, 119, 64)      0           ['multi_head_attention_4[0][0]'] \n                                                                                                  \n tf.__operators__.add_10 (TFOpL  (None, 119, 64)     0           ['lstm_3[0][0]',                 \n ambda)                                                           'dropout_8[0][0]']              \n                                                                                                  \n layer_normalization_8 (LayerNo  (None, 119, 64)     128         ['tf.__operators__.add_10[0][0]']\n rmalization)                                                                                     \n                                                                                                  \n dense_24 (Dense)               (None, 119, 128)     8320        ['layer_normalization_8[0][0]']  \n                                                                                                  \n dense_25 (Dense)               (None, 119, 64)      8256        ['dense_24[0][0]']               \n                                                                                                  \n dropout_9 (Dropout)            (None, 119, 64)      0           ['dense_25[0][0]']               \n                                                                                                  \n tf.__operators__.add_11 (TFOpL  (None, 119, 64)     0           ['layer_normalization_8[0][0]',  \n ambda)                                                           'dropout_9[0][0]']              \n                                                                                                  \n layer_normalization_9 (LayerNo  (None, 119, 64)     128         ['tf.__operators__.add_11[0][0]']\n rmalization)                                                                                     \n                                                                                                  \n global_average_pooling1d_4 (Gl  (None, 64)          0           ['layer_normalization_9[0][0]']  \n obalAveragePooling1D)                                                                            \n                                                                                                  \n dense_26 (Dense)               (None, 64)           4160        ['global_average_pooling1d_4[0][0\n                                                                 ]']                              \n                                                                                                  \n dense_27 (Dense)               (None, 1)            65          ['dense_26[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 116,353\nTrainable params: 116,353\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/30\n30/30 [==============================] - 7s 147ms/step - loss: 0.7025 - accuracy: 0.5582 - val_loss: 0.6924 - val_accuracy: 0.5000\nEpoch 2/30\n30/30 [==============================] - 4s 135ms/step - loss: 0.6643 - accuracy: 0.5960 - val_loss: 0.6880 - val_accuracy: 0.5755\nEpoch 3/30\n30/30 [==============================] - 4s 125ms/step - loss: 0.6715 - accuracy: 0.5876 - val_loss: 0.6883 - val_accuracy: 0.5189\nEpoch 4/30\n30/30 [==============================] - 4s 127ms/step - loss: 0.6531 - accuracy: 0.6191 - val_loss: 0.6947 - val_accuracy: 0.6038\nEpoch 5/30\n30/30 [==============================] - 4s 124ms/step - loss: 0.6421 - accuracy: 0.6390 - val_loss: 0.6863 - val_accuracy: 0.6038\nEpoch 6/30\n30/30 [==============================] - 4s 125ms/step - loss: 0.6326 - accuracy: 0.6243 - val_loss: 0.7091 - val_accuracy: 0.5660\nEpoch 7/30\n30/30 [==============================] - 4s 125ms/step - loss: 0.6244 - accuracy: 0.6306 - val_loss: 0.7147 - val_accuracy: 0.5189\nEpoch 8/30\n30/30 [==============================] - 4s 125ms/step - loss: 0.6077 - accuracy: 0.6558 - val_loss: 0.6946 - val_accuracy: 0.5660\nEpoch 9/30\n30/30 [==============================] - 4s 128ms/step - loss: 0.6155 - accuracy: 0.6569 - val_loss: 0.6696 - val_accuracy: 0.6321\nEpoch 10/30\n30/30 [==============================] - 4s 130ms/step - loss: 0.5806 - accuracy: 0.6905 - val_loss: 0.6551 - val_accuracy: 0.6792\nEpoch 11/30\n30/30 [==============================] - 4s 134ms/step - loss: 0.5853 - accuracy: 0.6863 - val_loss: 0.6533 - val_accuracy: 0.6509\nEpoch 12/30\n30/30 [==============================] - 4s 129ms/step - loss: 0.5663 - accuracy: 0.7041 - val_loss: 0.6176 - val_accuracy: 0.7075\nEpoch 13/30\n30/30 [==============================] - 4s 126ms/step - loss: 0.5454 - accuracy: 0.7009 - val_loss: 0.8273 - val_accuracy: 0.6226\nEpoch 14/30\n30/30 [==============================] - 4s 128ms/step - loss: 0.5909 - accuracy: 0.6967 - val_loss: 0.6978 - val_accuracy: 0.6038\nEpoch 15/30\n30/30 [==============================] - 4s 128ms/step - loss: 0.5440 - accuracy: 0.7114 - val_loss: 0.7390 - val_accuracy: 0.6321\nEpoch 16/30\n30/30 [==============================] - 4s 130ms/step - loss: 0.5245 - accuracy: 0.7408 - val_loss: 0.7537 - val_accuracy: 0.5755\nEpoch 17/30\n30/30 [==============================] - 4s 132ms/step - loss: 0.5116 - accuracy: 0.7492 - val_loss: 0.7099 - val_accuracy: 0.6226\nEpoch 18/30\n30/30 [==============================] - 4s 126ms/step - loss: 0.4983 - accuracy: 0.7419 - val_loss: 0.6985 - val_accuracy: 0.6698\nEpoch 19/30\n30/30 [==============================] - 4s 136ms/step - loss: 0.5002 - accuracy: 0.7356 - val_loss: 0.8251 - val_accuracy: 0.6132\nEpoch 20/30\n30/30 [==============================] - 4s 129ms/step - loss: 0.4733 - accuracy: 0.7639 - val_loss: 0.7276 - val_accuracy: 0.6887\nEpoch 21/30\n30/30 [==============================] - 4s 127ms/step - loss: 0.4640 - accuracy: 0.7692 - val_loss: 0.8382 - val_accuracy: 0.5472\nEpoch 22/30\n30/30 [==============================] - 4s 128ms/step - loss: 0.4382 - accuracy: 0.7891 - val_loss: 0.8607 - val_accuracy: 0.6321\nEpoch 23/30\n30/30 [==============================] - 4s 129ms/step - loss: 0.4061 - accuracy: 0.8101 - val_loss: 0.9180 - val_accuracy: 0.6321\nEpoch 24/30\n30/30 [==============================] - 4s 126ms/step - loss: 0.3835 - accuracy: 0.8300 - val_loss: 1.0017 - val_accuracy: 0.6321\nEpoch 25/30\n30/30 [==============================] - 4s 127ms/step - loss: 0.4098 - accuracy: 0.8090 - val_loss: 0.9083 - val_accuracy: 0.6226\nEpoch 26/30\n30/30 [==============================] - 4s 127ms/step - loss: 0.4030 - accuracy: 0.8164 - val_loss: 0.8673 - val_accuracy: 0.6604\nEpoch 27/30\n30/30 [==============================] - 4s 136ms/step - loss: 0.3598 - accuracy: 0.8290 - val_loss: 1.0048 - val_accuracy: 0.5755\nEpoch 28/30\n30/30 [==============================] - 4s 132ms/step - loss: 0.3106 - accuracy: 0.8667 - val_loss: 0.9639 - val_accuracy: 0.6604\nEpoch 29/30\n30/30 [==============================] - 4s 126ms/step - loss: 0.3043 - accuracy: 0.8741 - val_loss: 0.9029 - val_accuracy: 0.6698\nEpoch 30/30\n30/30 [==============================] - 4s 130ms/step - loss: 0.3323 - accuracy: 0.8468 - val_loss: 1.0145 - val_accuracy: 0.5849\nHighest accuracy: 0.7075471878051758\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"### **LSTM + Transformer + Additive Fusion** (Combines the LSTM output and the Transformer output using the Add layer)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling1D, Add\n\n\n# Ensure TensorFlow is using the GPU\ndef setup_gpu():\n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        try:\n            # Currently, memory growth needs to be the same across GPUs\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n        except RuntimeError as e:\n            # Memory growth must be set before GPUs have been initialized\n            print(e)\n\nsetup_gpu()\n\ndef positional_encoding(sequence_length, model_dim):\n    position = np.arange(sequence_length)[:, np.newaxis]\n    div_term = np.exp(np.arange(0, model_dim, 2) * -(np.log(10000.0) / model_dim))\n    pos_encoding = np.zeros((sequence_length, model_dim))\n    pos_encoding[:, 0::2] = np.sin(position * div_term)\n    pos_encoding[:, 1::2] = np.cos(position * div_term)\n    return tf.constant(pos_encoding, dtype=tf.float32)\n\n# Apply positional encoding\ninputs = Input(shape=(train_data.shape[1], train_data.shape[2]))\npos_encoding = positional_encoding(train_data.shape[1], train_data.shape[2])\nx = inputs + pos_encoding\nx_lstm = LSTM(128, return_sequences=True)(inputs)\nx_transformer = transformer_encoder(x_lstm, num_heads=4, ff_dim=128, dropout_rate=0.1)\nx = Add()([x_lstm, x_transformer])\nx = GlobalAveragePooling1D()(x)\nx = Dense(64, activation=\"relu\")(x)\noutput = Dense(1, activation=\"sigmoid\")(x)\nhybrid_model = Model(inputs, output)\n\nhybrid_model.summary()\n\n# -------- Compile and train Transformer model --------\n\noptimizer = Adam(learning_rate=0.0001)\nhybrid_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Optionally, specify the GPU device (if multiple GPUs are available)\nwith tf.device('/device:GPU:0'):  # Use '/device:GPU:1' for a second GPU, etc.\n    history = hybrid_model.fit(train_data, train_labels,\n                               epochs=40,\n                               batch_size=16,\n                               validation_data=(test_data, test_labels))\n\nprint(\"Highest accuracy: \" + str(max(history.history['val_accuracy'])))\nhybrid_model.save(\"/kaggle/working/Results/Transformer_model/Transformer_hybrid_model_2_arousal.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T14:22:23.074233Z","iopub.execute_input":"2024-11-28T14:22:23.074911Z","iopub.status.idle":"2024-11-28T14:28:51.120390Z","shell.execute_reply.started":"2024-11-28T14:22:23.074879Z","shell.execute_reply":"2024-11-28T14:28:51.119282Z"}},"outputs":[{"name":"stdout","text":"Model: \"model_15\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_16 (InputLayer)          [(None, 119, 48)]    0           []                               \n                                                                                                  \n lstm_9 (LSTM)                  (None, 119, 128)     90624       ['input_16[0][0]']               \n                                                                                                  \n multi_head_attention_10 (Multi  (None, 119, 128)    263808      ['lstm_9[0][0]',                 \n HeadAttention)                                                   'lstm_9[0][0]']                 \n                                                                                                  \n dropout_20 (Dropout)           (None, 119, 128)     0           ['multi_head_attention_10[0][0]']\n                                                                                                  \n tf.__operators__.add_28 (TFOpL  (None, 119, 128)    0           ['lstm_9[0][0]',                 \n ambda)                                                           'dropout_20[0][0]']             \n                                                                                                  \n layer_normalization_20 (LayerN  (None, 119, 128)    256         ['tf.__operators__.add_28[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n dense_46 (Dense)               (None, 119, 128)     16512       ['layer_normalization_20[0][0]'] \n                                                                                                  \n dense_47 (Dense)               (None, 119, 128)     16512       ['dense_46[0][0]']               \n                                                                                                  \n dropout_21 (Dropout)           (None, 119, 128)     0           ['dense_47[0][0]']               \n                                                                                                  \n tf.__operators__.add_29 (TFOpL  (None, 119, 128)    0           ['layer_normalization_20[0][0]', \n ambda)                                                           'dropout_21[0][0]']             \n                                                                                                  \n layer_normalization_21 (LayerN  (None, 119, 128)    256         ['tf.__operators__.add_29[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n add (Add)                      (None, 119, 128)     0           ['lstm_9[0][0]',                 \n                                                                  'layer_normalization_21[0][0]'] \n                                                                                                  \n global_average_pooling1d_9 (Gl  (None, 128)         0           ['add[0][0]']                    \n obalAveragePooling1D)                                                                            \n                                                                                                  \n dense_48 (Dense)               (None, 64)           8256        ['global_average_pooling1d_9[0][0\n                                                                 ]']                              \n                                                                                                  \n dense_49 (Dense)               (None, 1)            65          ['dense_48[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 396,289\nTrainable params: 396,289\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/40\n60/60 [==============================] - 13s 171ms/step - loss: 0.7222 - accuracy: 0.5404 - val_loss: 0.6988 - val_accuracy: 0.5566\nEpoch 2/40\n60/60 [==============================] - 10s 163ms/step - loss: 0.6599 - accuracy: 0.6086 - val_loss: 0.6863 - val_accuracy: 0.5849\nEpoch 3/40\n60/60 [==============================] - 9s 157ms/step - loss: 0.6463 - accuracy: 0.6390 - val_loss: 0.6806 - val_accuracy: 0.5283\nEpoch 4/40\n60/60 [==============================] - 9s 157ms/step - loss: 0.6302 - accuracy: 0.6516 - val_loss: 0.6614 - val_accuracy: 0.6038\nEpoch 5/40\n60/60 [==============================] - 10s 164ms/step - loss: 0.6114 - accuracy: 0.6569 - val_loss: 0.6755 - val_accuracy: 0.6038\nEpoch 6/40\n60/60 [==============================] - 9s 157ms/step - loss: 0.6080 - accuracy: 0.6621 - val_loss: 0.6681 - val_accuracy: 0.6226\nEpoch 7/40\n60/60 [==============================] - 9s 157ms/step - loss: 0.5954 - accuracy: 0.6600 - val_loss: 0.6665 - val_accuracy: 0.5849\nEpoch 8/40\n60/60 [==============================] - 9s 156ms/step - loss: 0.5853 - accuracy: 0.6884 - val_loss: 0.6478 - val_accuracy: 0.6226\nEpoch 9/40\n60/60 [==============================] - 10s 162ms/step - loss: 0.5774 - accuracy: 0.6905 - val_loss: 0.6380 - val_accuracy: 0.6604\nEpoch 10/40\n60/60 [==============================] - 10s 160ms/step - loss: 0.5647 - accuracy: 0.6884 - val_loss: 0.6271 - val_accuracy: 0.6509\nEpoch 11/40\n60/60 [==============================] - 10s 159ms/step - loss: 0.5476 - accuracy: 0.7072 - val_loss: 0.6559 - val_accuracy: 0.6604\nEpoch 12/40\n60/60 [==============================] - 10s 164ms/step - loss: 0.5398 - accuracy: 0.7135 - val_loss: 0.6233 - val_accuracy: 0.6604\nEpoch 13/40\n60/60 [==============================] - 10s 159ms/step - loss: 0.5364 - accuracy: 0.7135 - val_loss: 0.6477 - val_accuracy: 0.6698\nEpoch 14/40\n60/60 [==============================] - 10s 159ms/step - loss: 0.5225 - accuracy: 0.7377 - val_loss: 0.6204 - val_accuracy: 0.6698\nEpoch 15/40\n60/60 [==============================] - 10s 161ms/step - loss: 0.5151 - accuracy: 0.7356 - val_loss: 0.6455 - val_accuracy: 0.6415\nEpoch 16/40\n60/60 [==============================] - 10s 160ms/step - loss: 0.5067 - accuracy: 0.7471 - val_loss: 0.6780 - val_accuracy: 0.6792\nEpoch 17/40\n60/60 [==============================] - 9s 158ms/step - loss: 0.4930 - accuracy: 0.7587 - val_loss: 0.6526 - val_accuracy: 0.6698\nEpoch 18/40\n60/60 [==============================] - 10s 159ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.6540 - val_accuracy: 0.6887\nEpoch 19/40\n60/60 [==============================] - 10s 164ms/step - loss: 0.4728 - accuracy: 0.7639 - val_loss: 0.6242 - val_accuracy: 0.6887\nEpoch 20/40\n60/60 [==============================] - 9s 158ms/step - loss: 0.4589 - accuracy: 0.7587 - val_loss: 0.6804 - val_accuracy: 0.6887\nEpoch 21/40\n60/60 [==============================] - 9s 158ms/step - loss: 0.4498 - accuracy: 0.7828 - val_loss: 0.6584 - val_accuracy: 0.6887\nEpoch 22/40\n60/60 [==============================] - 10s 163ms/step - loss: 0.4509 - accuracy: 0.7828 - val_loss: 0.6992 - val_accuracy: 0.6509\nEpoch 23/40\n60/60 [==============================] - 9s 158ms/step - loss: 0.4315 - accuracy: 0.7901 - val_loss: 0.6691 - val_accuracy: 0.7264\nEpoch 24/40\n60/60 [==============================] - 10s 159ms/step - loss: 0.4204 - accuracy: 0.8143 - val_loss: 0.7082 - val_accuracy: 0.6698\nEpoch 25/40\n60/60 [==============================] - 9s 158ms/step - loss: 0.4134 - accuracy: 0.7954 - val_loss: 0.6634 - val_accuracy: 0.7264\nEpoch 26/40\n60/60 [==============================] - 10s 165ms/step - loss: 0.3909 - accuracy: 0.8132 - val_loss: 0.7511 - val_accuracy: 0.6887\nEpoch 27/40\n60/60 [==============================] - 10s 159ms/step - loss: 0.3887 - accuracy: 0.8143 - val_loss: 0.7074 - val_accuracy: 0.6792\nEpoch 28/40\n60/60 [==============================] - 9s 158ms/step - loss: 0.3710 - accuracy: 0.8342 - val_loss: 0.7132 - val_accuracy: 0.7075\nEpoch 29/40\n60/60 [==============================] - 10s 164ms/step - loss: 0.3687 - accuracy: 0.8342 - val_loss: 0.6942 - val_accuracy: 0.6509\nEpoch 30/40\n60/60 [==============================] - 10s 159ms/step - loss: 0.3419 - accuracy: 0.8447 - val_loss: 0.7208 - val_accuracy: 0.7358\nEpoch 31/40\n60/60 [==============================] - 10s 159ms/step - loss: 0.3330 - accuracy: 0.8552 - val_loss: 0.7537 - val_accuracy: 0.7075\nEpoch 32/40\n60/60 [==============================] - 10s 165ms/step - loss: 0.3360 - accuracy: 0.8583 - val_loss: 0.7917 - val_accuracy: 0.6887\nEpoch 33/40\n60/60 [==============================] - 9s 156ms/step - loss: 0.3212 - accuracy: 0.8531 - val_loss: 0.7514 - val_accuracy: 0.7075\nEpoch 34/40\n60/60 [==============================] - 9s 158ms/step - loss: 0.3045 - accuracy: 0.8688 - val_loss: 0.8117 - val_accuracy: 0.6981\nEpoch 35/40\n60/60 [==============================] - 9s 158ms/step - loss: 0.2993 - accuracy: 0.8783 - val_loss: 0.7959 - val_accuracy: 0.7264\nEpoch 36/40\n60/60 [==============================] - 10s 165ms/step - loss: 0.2669 - accuracy: 0.8919 - val_loss: 0.7835 - val_accuracy: 0.6981\nEpoch 37/40\n60/60 [==============================] - 10s 161ms/step - loss: 0.2657 - accuracy: 0.8972 - val_loss: 0.8688 - val_accuracy: 0.7264\nEpoch 38/40\n60/60 [==============================] - 10s 161ms/step - loss: 0.2554 - accuracy: 0.8982 - val_loss: 0.8065 - val_accuracy: 0.7264\nEpoch 39/40\n60/60 [==============================] - 10s 166ms/step - loss: 0.2337 - accuracy: 0.9014 - val_loss: 0.8414 - val_accuracy: 0.7170\nEpoch 40/40\n60/60 [==============================] - 10s 160ms/step - loss: 0.2173 - accuracy: 0.9098 - val_loss: 0.8692 - val_accuracy: 0.7075\nHighest accuracy: 0.7358490824699402\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"## Arousal Model","metadata":{}},{"cell_type":"code","source":"all_labels, all_data = load_np_data(dimension=\"arousal\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:30:17.176257Z","iopub.execute_input":"2024-11-24T13:30:17.176521Z","iopub.status.idle":"2024-11-24T13:30:17.849011Z","shell.execute_reply.started":"2024-11-24T13:30:17.176495Z","shell.execute_reply":"2024-11-24T13:30:17.848094Z"}},"outputs":[{"name":"stdout","text":"Total arousal:  (1082,) (1082, 32, 7680)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Shuffle and prepare all data\nall_data, all_labels = shuffle(all_data, all_labels, random_state=0)\nprint(all_data.shape, all_labels.shape)\n\n# Transform all data to vector form\nall_vectors = vector_transform(all_data)\nprint(all_vectors.shape)\n\n# -------- Create new autoencoder --------\ninput_layer = Input(shape=(32,))\nencoded = Dense(64, activation=None)(input_layer)\nbottleneck_layer = Dense(bottleneck, activation=None)(encoded)\ndecoded = Dense(64, activation=None)(bottleneck_layer)\ndecoded = Dense(32, activation=None)(decoded)\nautoencoder = Model(input_layer, decoded)\nautoencoder.summary()\n\nencoder = Model(input_layer, bottleneck_layer)\nencoder.summary()\n\ndecoder_input_layer = Input(shape=(bottleneck,))\ndecoder_layer = autoencoder.layers[-2](decoder_input_layer)\ndecoder_layer = autoencoder.layers[-1](decoder_layer)\ndecoder = Model(decoder_input_layer, decoder_layer)\ndecoder.summary()\n\n# -------- Compile and train autoencoder --------\nautoencoder.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\nautoencoder.fit(all_vectors, all_vectors, epochs=1, batch_size=64, shuffle=True, validation_split=0.1)\nautoencoder.save(\"/kaggle/working/Results/autoencoder_model/autoencoder_model_arousal.h5\")\n\n# -------- Encode all data --------\nall_data_encoded = encoder.predict(all_vectors)\nall_data_encoded = inverse_vector_transform(all_data_encoded)\nprint(\"Encoded data shape: \", all_data_encoded.shape)\n\n# -------- Feature extraction from 12 source signals --------\nall_band_power = []\nfor data in all_data_encoded:  # For every trial\n    with io.capture_output() as captured:\n        trial_band_power = trial_psd_extraction_integration(data)\n    all_band_power.append(trial_band_power)\nall_band_power = np.array(all_band_power)\nprint(\"All features shape: \", all_band_power.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:30:17.852286Z","iopub.execute_input":"2024-11-24T13:30:17.852562Z","iopub.status.idle":"2024-11-24T13:40:18.591065Z","shell.execute_reply.started":"2024-11-24T13:30:17.852536Z","shell.execute_reply":"2024-11-24T13:40:18.590106Z"}},"outputs":[{"name":"stdout","text":"(1082, 32, 7680) (1082,)\n(8309760, 32)\nModel: \"model_44\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_34 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_77 (Dense)            (None, 64)                2112      \n                                                                 \n dense_78 (Dense)            (None, 12)                780       \n                                                                 \n dense_79 (Dense)            (None, 64)                832       \n                                                                 \n dense_80 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_45\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_34 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_77 (Dense)            (None, 64)                2112      \n                                                                 \n dense_78 (Dense)            (None, 12)                780       \n                                                                 \n=================================================================\nTotal params: 2,892\nTrainable params: 2,892\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model_46\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_35 (InputLayer)       [(None, 12)]              0         \n                                                                 \n dense_79 (Dense)            (None, 64)                832       \n                                                                 \n dense_80 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 2,912\nTrainable params: 2,912\nNon-trainable params: 0\n_________________________________________________________________\n259680/259680 [==============================] - 241s 926us/step\nEncoded data shape:  (1082, 12, 7680)\nAll features shape:  (1082, 119, 48)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# -------- Train-test split --------\ntrain_data, test_data, train_labels, test_labels = train_test_split(all_band_power, all_labels, test_size=0.1, random_state=42)\nprint(train_data.shape, test_data.shape)\n\n# -------- Create new LSTM model --------\nx = Input(shape=(n_segment, bottleneck * 4))\nx1 = LSTM(n_segment)(x)\nx2 = Dense(n_segment)(x1)\nx3 = Dense(12)(x2)\noutput = Dense(1, activation=\"sigmoid\")(x2)\nmodel = Model(x, output)\n\n# -------- Compile and train LSTM --------\nmodel.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\nhistory = model.fit(train_data, train_labels, epochs=30, batch_size=8, validation_data=(test_data, test_labels))\nprint(\"Highest accuracy: \" + str(max(history.history['val_accuracy'])))\nmodel.save(\"/kaggle/working/Results/LSTM_model/LSTM_model_arousal.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T13:40:18.592435Z","iopub.execute_input":"2024-11-24T13:40:18.593209Z","iopub.status.idle":"2024-11-24T13:44:02.672975Z","shell.execute_reply.started":"2024-11-24T13:40:18.593144Z","shell.execute_reply":"2024-11-24T13:44:02.672226Z"}},"outputs":[{"name":"stdout","text":"(973, 119, 48) (109, 119, 48)\nEpoch 1/30\n122/122 [==============================] - 10s 69ms/step - loss: 0.2466 - accuracy: 0.5591 - val_loss: 0.2292 - val_accuracy: 0.6514\nEpoch 2/30\n122/122 [==============================] - 8s 62ms/step - loss: 0.2281 - accuracy: 0.6321 - val_loss: 0.2271 - val_accuracy: 0.6514\nEpoch 3/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.2192 - accuracy: 0.6660 - val_loss: 0.2250 - val_accuracy: 0.6422\nEpoch 4/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.2127 - accuracy: 0.6814 - val_loss: 0.2227 - val_accuracy: 0.6514\nEpoch 5/30\n122/122 [==============================] - 7s 61ms/step - loss: 0.2070 - accuracy: 0.6989 - val_loss: 0.2273 - val_accuracy: 0.6330\nEpoch 6/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.2032 - accuracy: 0.7020 - val_loss: 0.2248 - val_accuracy: 0.6514\nEpoch 7/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1978 - accuracy: 0.7143 - val_loss: 0.2240 - val_accuracy: 0.6514\nEpoch 8/30\n122/122 [==============================] - 7s 59ms/step - loss: 0.1929 - accuracy: 0.7235 - val_loss: 0.2265 - val_accuracy: 0.6606\nEpoch 9/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1892 - accuracy: 0.7338 - val_loss: 0.2239 - val_accuracy: 0.6789\nEpoch 10/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1856 - accuracy: 0.7328 - val_loss: 0.2247 - val_accuracy: 0.6422\nEpoch 11/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1821 - accuracy: 0.7451 - val_loss: 0.2284 - val_accuracy: 0.6330\nEpoch 12/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1773 - accuracy: 0.7523 - val_loss: 0.2340 - val_accuracy: 0.5872\nEpoch 13/30\n122/122 [==============================] - 7s 61ms/step - loss: 0.1749 - accuracy: 0.7503 - val_loss: 0.2280 - val_accuracy: 0.6514\nEpoch 14/30\n122/122 [==============================] - 7s 61ms/step - loss: 0.1720 - accuracy: 0.7575 - val_loss: 0.2280 - val_accuracy: 0.6514\nEpoch 15/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1665 - accuracy: 0.7616 - val_loss: 0.2281 - val_accuracy: 0.6697\nEpoch 16/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1643 - accuracy: 0.7852 - val_loss: 0.2251 - val_accuracy: 0.6789\nEpoch 17/30\n122/122 [==============================] - 7s 59ms/step - loss: 0.1612 - accuracy: 0.7698 - val_loss: 0.2318 - val_accuracy: 0.6422\nEpoch 18/30\n122/122 [==============================] - 7s 59ms/step - loss: 0.1547 - accuracy: 0.7965 - val_loss: 0.2219 - val_accuracy: 0.6330\nEpoch 19/30\n122/122 [==============================] - 8s 62ms/step - loss: 0.1509 - accuracy: 0.7955 - val_loss: 0.2283 - val_accuracy: 0.6422\nEpoch 20/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1472 - accuracy: 0.8109 - val_loss: 0.2252 - val_accuracy: 0.6606\nEpoch 21/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1431 - accuracy: 0.8099 - val_loss: 0.2307 - val_accuracy: 0.6330\nEpoch 22/30\n122/122 [==============================] - 7s 59ms/step - loss: 0.1385 - accuracy: 0.8160 - val_loss: 0.2354 - val_accuracy: 0.6606\nEpoch 23/30\n122/122 [==============================] - 7s 61ms/step - loss: 0.1362 - accuracy: 0.8325 - val_loss: 0.2352 - val_accuracy: 0.6330\nEpoch 24/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1338 - accuracy: 0.8356 - val_loss: 0.2371 - val_accuracy: 0.6330\nEpoch 25/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1269 - accuracy: 0.8356 - val_loss: 0.2288 - val_accuracy: 0.6606\nEpoch 26/30\n122/122 [==============================] - 7s 61ms/step - loss: 0.1239 - accuracy: 0.8499 - val_loss: 0.2450 - val_accuracy: 0.6239\nEpoch 27/30\n122/122 [==============================] - 7s 61ms/step - loss: 0.1226 - accuracy: 0.8561 - val_loss: 0.2406 - val_accuracy: 0.6422\nEpoch 28/30\n122/122 [==============================] - 7s 60ms/step - loss: 0.1155 - accuracy: 0.8654 - val_loss: 0.2326 - val_accuracy: 0.6422\nEpoch 29/30\n122/122 [==============================] - 7s 61ms/step - loss: 0.1131 - accuracy: 0.8705 - val_loss: 0.2461 - val_accuracy: 0.6055\nEpoch 30/30\n122/122 [==============================] - 7s 61ms/step - loss: 0.1074 - accuracy: 0.8756 - val_loss: 0.2492 - val_accuracy: 0.6422\nHighest accuracy: 0.6788991093635559\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Final models tesing","metadata":{}},{"cell_type":"code","source":"valence_labels, valence_data, arousal_labels, arousal_data = convertOneData(\"/kaggle/input/data_preprocessed_python/s01.dat\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:35.690784Z","iopub.execute_input":"2024-11-24T14:07:35.691182Z","iopub.status.idle":"2024-11-24T14:07:36.533028Z","shell.execute_reply.started":"2024-11-24T14:07:35.691139Z","shell.execute_reply":"2024-11-24T14:07:36.532150Z"}},"outputs":[{"name":"stdout","text":"valence:  38 arousal:  39\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"arousal_d = standardise_2D(arousal_data, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:38.573640Z","iopub.execute_input":"2024-11-24T14:07:38.574314Z","iopub.status.idle":"2024-11-24T14:07:38.751007Z","shell.execute_reply.started":"2024-11-24T14:07:38.574279Z","shell.execute_reply":"2024-11-24T14:07:38.750000Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"arousal_d.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:39.002000Z","iopub.execute_input":"2024-11-24T14:07:39.002684Z","iopub.status.idle":"2024-11-24T14:07:39.008089Z","shell.execute_reply.started":"2024-11-24T14:07:39.002649Z","shell.execute_reply":"2024-11-24T14:07:39.007160Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(39, 32, 7680)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"arousal_data_vectors = vector_transform(arousal_d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:39.316311Z","iopub.execute_input":"2024-11-24T14:07:39.316585Z","iopub.status.idle":"2024-11-24T14:07:39.351982Z","shell.execute_reply.started":"2024-11-24T14:07:39.316559Z","shell.execute_reply":"2024-11-24T14:07:39.351012Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"encoder_path = \"/kaggle/working/Results/autoencoder_model/autoencoder_model_test_fold_0.h5\"\nlstm_path = \"/kaggle/working/Results/LSTM_model/LSTM_model_test_fold_0.h5\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:39.530820Z","iopub.execute_input":"2024-11-24T14:07:39.531144Z","iopub.status.idle":"2024-11-24T14:07:39.535242Z","shell.execute_reply.started":"2024-11-24T14:07:39.531103Z","shell.execute_reply":"2024-11-24T14:07:39.534337Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"encoder = load_model(encoder_path)\nlstm_model = load_model(lstm_path)\nencoder_model = Model(encoder.input, encoder.get_layer('dense_1').output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:39.862447Z","iopub.execute_input":"2024-11-24T14:07:39.862770Z","iopub.status.idle":"2024-11-24T14:07:40.236108Z","shell.execute_reply.started":"2024-11-24T14:07:39.862741Z","shell.execute_reply":"2024-11-24T14:07:40.235349Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"arousal_data_vectors.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:40.237452Z","iopub.execute_input":"2024-11-24T14:07:40.237710Z","iopub.status.idle":"2024-11-24T14:07:40.243682Z","shell.execute_reply.started":"2024-11-24T14:07:40.237684Z","shell.execute_reply":"2024-11-24T14:07:40.242728Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(299520, 32)"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"arousal_encoded = encoder_model.predict(arousal_data_vectors)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:40.574324Z","iopub.execute_input":"2024-11-24T14:07:40.574850Z","iopub.status.idle":"2024-11-24T14:07:55.099102Z","shell.execute_reply.started":"2024-11-24T14:07:40.574817Z","shell.execute_reply":"2024-11-24T14:07:55.098142Z"}},"outputs":[{"name":"stdout","text":"9360/9360 [==============================] - 9s 939us/step\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"arousal_data_inverted = inverse_vector_transform(arousal_encoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:55.102410Z","iopub.execute_input":"2024-11-24T14:07:55.102806Z","iopub.status.idle":"2024-11-24T14:07:55.106728Z","shell.execute_reply.started":"2024-11-24T14:07:55.102778Z","shell.execute_reply":"2024-11-24T14:07:55.105938Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"arousal_features = []\nfor data in arousal_data_inverted:\n    features = trial_psd_extraction_integration(data)\n    arousal_features.append(features)\narousal_features = np.array(arousal_features)\n\npredictions = lstm_model.predict(arousal_features)\n\n# Print a few random predictions\nfor i in range(0, len(predictions)):\n    print(f\"Prediction: {predictions[i][0]:.2f}, Ground Truth: {arousal_labels[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:07:55.107682Z","iopub.execute_input":"2024-11-24T14:07:55.107891Z","iopub.status.idle":"2024-11-24T14:07:57.220548Z","shell.execute_reply.started":"2024-11-24T14:07:55.107870Z","shell.execute_reply":"2024-11-24T14:07:57.219713Z"}},"outputs":[{"name":"stdout","text":"Creating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\n2/2 [==============================] - 1s 15ms/step\nPrediction: 0.75, Ground Truth: 1\nPrediction: 0.87, Ground Truth: 1\nPrediction: 0.70, Ground Truth: 1\nPrediction: 0.95, Ground Truth: 1\nPrediction: 0.61, Ground Truth: 0\nPrediction: 0.95, Ground Truth: 0\nPrediction: 0.90, Ground Truth: 0\nPrediction: 0.94, Ground Truth: 0\nPrediction: 0.49, Ground Truth: 0\nPrediction: 0.53, Ground Truth: 0\nPrediction: 0.59, Ground Truth: 0\nPrediction: 0.48, Ground Truth: 0\nPrediction: 0.57, Ground Truth: 0\nPrediction: 0.44, Ground Truth: 1\nPrediction: 0.79, Ground Truth: 1\nPrediction: 0.59, Ground Truth: 1\nPrediction: 0.84, Ground Truth: 1\nPrediction: 0.96, Ground Truth: 1\nPrediction: 0.86, Ground Truth: 1\nPrediction: 0.93, Ground Truth: 1\nPrediction: 0.92, Ground Truth: 0\nPrediction: 0.85, Ground Truth: 0\nPrediction: 0.95, Ground Truth: 1\nPrediction: 0.87, Ground Truth: 1\nPrediction: 0.90, Ground Truth: 1\nPrediction: 0.89, Ground Truth: 1\nPrediction: 0.92, Ground Truth: 0\nPrediction: 0.45, Ground Truth: 0\nPrediction: 0.69, Ground Truth: 0\nPrediction: 0.55, Ground Truth: 1\nPrediction: 0.32, Ground Truth: 1\nPrediction: 0.60, Ground Truth: 0\nPrediction: 0.25, Ground Truth: 1\nPrediction: 0.76, Ground Truth: 1\nPrediction: 0.78, Ground Truth: 1\nPrediction: 0.47, Ground Truth: 1\nPrediction: 0.48, Ground Truth: 1\nPrediction: 0.55, Ground Truth: 1\nPrediction: 0.64, Ground Truth: 1\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# Emotion Detection based on the created models","metadata":{}},{"cell_type":"code","source":"def map_to_emotion(valence_pred, arousal_pred):\n    if valence_pred == 1 and arousal_pred == 1:\n        return \"Happy\"  # High Valence, High Arousal\n    elif valence_pred == 1 and arousal_pred == 0:\n        return \"Content\"  # High Valence, Low Arousal\n    elif valence_pred == 0 and arousal_pred == 1:\n        return \"Angry\"  # Low Valence, High Arousal\n    elif valence_pred == 0 and arousal_pred == 0:\n        return \"Sad\"  # Low Valence, Low Arousal\n    else:\n        return \"Unknown\"  # For safety\n\naraousel_encoder_path = \"/kaggle/working/Results/autoencoder_model/autoencoder_model_arousal.h5\"\nvalence_encoder_path = \"/kaggle/working/Results/autoencoder_model/autoencoder_model_valence.h5\"\n\nlstm_valence_path = \"/kaggle/working/Results/LSTM_model/LSTM_model_valence.h5\"\nlstm_araousel_path = \"/kaggle/working/Results/LSTM_model/LSTM_model_arousal.h5\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:23:27.556986Z","iopub.execute_input":"2024-11-24T14:23:27.557810Z","iopub.status.idle":"2024-11-24T14:23:27.563050Z","shell.execute_reply.started":"2024-11-24T14:23:27.557776Z","shell.execute_reply":"2024-11-24T14:23:27.562024Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"araousel_encoder = load_model(araousel_encoder_path)\naraousel_lstm_model = load_model(lstm_araousel_path)\n\naraousel_encoder.summary()\naraousel_encoder = Model(araousel_encoder.input, araousel_encoder.get_layer('dense_78').output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:20:18.276589Z","iopub.execute_input":"2024-11-24T14:20:18.276963Z","iopub.status.idle":"2024-11-24T14:20:18.640389Z","shell.execute_reply.started":"2024-11-24T14:20:18.276932Z","shell.execute_reply":"2024-11-24T14:20:18.639576Z"}},"outputs":[{"name":"stdout","text":"Model: \"model_44\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_34 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_77 (Dense)            (None, 64)                2112      \n                                                                 \n dense_78 (Dense)            (None, 12)                780       \n                                                                 \n dense_79 (Dense)            (None, 64)                832       \n                                                                 \n dense_80 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"valence_encoder = load_model(valence_encoder_path)\nvalence_lstm_model = load_model(lstm_valence_path)\n\nvalence_encoder.summary()\nvalence_encoder = Model(valence_encoder.input, valence_encoder.get_layer('dense_71').output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:23:37.298215Z","iopub.execute_input":"2024-11-24T14:23:37.298907Z","iopub.status.idle":"2024-11-24T14:23:37.639139Z","shell.execute_reply.started":"2024-11-24T14:23:37.298874Z","shell.execute_reply":"2024-11-24T14:23:37.638336Z"}},"outputs":[{"name":"stdout","text":"Model: \"model_40\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_31 (InputLayer)       [(None, 32)]              0         \n                                                                 \n dense_70 (Dense)            (None, 64)                2112      \n                                                                 \n dense_71 (Dense)            (None, 12)                780       \n                                                                 \n dense_72 (Dense)            (None, 64)                832       \n                                                                 \n dense_73 (Dense)            (None, 32)                2080      \n                                                                 \n=================================================================\nTotal params: 5,804\nTrainable params: 5,804\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"valence_labels, valence_data, arousal_labels, arousal_data = convertOneData(\"/kaggle/input/data_preprocessed_python/s01.dat\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:23:55.845007Z","iopub.execute_input":"2024-11-24T14:23:55.845374Z","iopub.status.idle":"2024-11-24T14:23:56.141266Z","shell.execute_reply.started":"2024-11-24T14:23:55.845333Z","shell.execute_reply":"2024-11-24T14:23:56.140359Z"}},"outputs":[{"name":"stdout","text":"valence:  38 arousal:  39\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"valence_d = standardise_2D(valence_data, 1)\nvalence_data_vectors = vector_transform(valence_d)\nvalence_encoded = valence_encoder.predict(valence_data_vectors)\n\nvalence_data_inverted = inverse_vector_transform(valence_encoded)\nvalence_features = [trial_psd_extraction_integration(data) for data in valence_data_inverted]\nvalence_features = np.array(valence_features)\nvalence_predictions = valence_lstm_model.predict(valence_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:23:58.503220Z","iopub.execute_input":"2024-11-24T14:23:58.503557Z","iopub.status.idle":"2024-11-24T14:24:14.524400Z","shell.execute_reply.started":"2024-11-24T14:23:58.503531Z","shell.execute_reply":"2024-11-24T14:24:14.523708Z"}},"outputs":[{"name":"stdout","text":"9120/9120 [==============================] - 9s 929us/step\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\n2/2 [==============================] - 0s 13ms/step\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"arousal_d = standardise_2D(arousal_data, 1)\narousal_data_vectors = vector_transform(arousal_d)\narousal_encoded = araousel_encoder.predict(arousal_data_vectors)\n\narousal_data_inverted = inverse_vector_transform(arousal_encoded)\narousal_features = [trial_psd_extraction_integration(data) for data in arousal_data_inverted]\narousal_features = np.array(arousal_features)\narousal_predictions = araousel_lstm_model.predict(arousal_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:24:14.526997Z","iopub.execute_input":"2024-11-24T14:24:14.527606Z","iopub.status.idle":"2024-11-24T14:24:28.177852Z","shell.execute_reply.started":"2024-11-24T14:24:14.527569Z","shell.execute_reply":"2024-11-24T14:24:28.177122Z"}},"outputs":[{"name":"stdout","text":"9360/9360 [==============================] - 9s 925us/step\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\nCreating RawArray with float64 data, n_channels=12, n_times=7680\n    Range : 0 ... 7679 =      0.000 ...    59.992 secs\nReady.\nEffective window size : 1.000 (s)\n2/2 [==============================] - 1s 15ms/step\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"combined_predictions = []\nfor i in range(len(valence_predictions)):\n    valence_pred = 1 if valence_predictions[i][0] > 0.5 else 0\n    arousal_pred = 1 if arousal_predictions[i][0] > 0.5 else 0\n    emotion = map_to_emotion(valence_pred, arousal_pred)\n    combined_predictions.append(emotion)\n    print(f\"Valence: {valence_pred}, Arousal: {arousal_pred}, Emotion: {emotion}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:24:28.179597Z","iopub.execute_input":"2024-11-24T14:24:28.180468Z","iopub.status.idle":"2024-11-24T14:24:28.186640Z","shell.execute_reply.started":"2024-11-24T14:24:28.180421Z","shell.execute_reply":"2024-11-24T14:24:28.185778Z"}},"outputs":[{"name":"stdout","text":"Valence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 0, Emotion: Content\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 0, Emotion: Content\nValence: 1, Arousal: 0, Emotion: Content\nValence: 1, Arousal: 0, Emotion: Content\nValence: 0, Arousal: 0, Emotion: Sad\nValence: 1, Arousal: 0, Emotion: Content\nValence: 0, Arousal: 0, Emotion: Sad\nValence: 1, Arousal: 0, Emotion: Content\nValence: 0, Arousal: 0, Emotion: Sad\nValence: 0, Arousal: 1, Emotion: Angry\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 0, Arousal: 0, Emotion: Sad\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 0, Arousal: 1, Emotion: Angry\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 0, Emotion: Content\nValence: 1, Arousal: 0, Emotion: Content\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 0, Arousal: 0, Emotion: Sad\nValence: 0, Arousal: 0, Emotion: Sad\nValence: 1, Arousal: 0, Emotion: Content\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 0, Arousal: 1, Emotion: Angry\nValence: 1, Arousal: 0, Emotion: Content\nValence: 0, Arousal: 1, Emotion: Angry\nValence: 0, Arousal: 1, Emotion: Angry\nValence: 0, Arousal: 1, Emotion: Angry\nValence: 0, Arousal: 1, Emotion: Angry\nValence: 1, Arousal: 1, Emotion: Happy\nValence: 0, Arousal: 1, Emotion: Angry\n","output_type":"stream"}],"execution_count":56}]}